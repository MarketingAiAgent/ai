from __future__ import annotations

import json
import textwrap
import logging
from typing import List, Optional, Dict, Any, Literal, TypedDict, Union
from concurrent.futures import ThreadPoolExecutor
from datetime import timedelta

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers.pydantic import PydanticOutputParser
from langgraph.graph import StateGraph, END

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_anthropic import ChatAnthropic

from app.core.config import settings
from app.database.promotion_slots import update_state
from app.agents.promotion.state import get_action_state
from app.agents.visualizer.graph import build_visualize_graph
from app.agents.visualizer.state import VisualizeState
from .state import *
from .tools import *
from .helpers import *

logger = logging.getLogger(__name__)

# ===== Nodes =====
def _generate_llm_recommendations(state: OrchestratorState, rows: List[Dict[str, Any]], knowledge: Dict[str, Any]) -> List[Dict[str, Any]]:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ DB ë°ì´í„°ì™€ ì§€ì‹ ìŠ¤ëƒ…ìƒ·ì„ ê¸°ë°˜ìœ¼ë¡œ 5ê°œ ì¶”ì²œ ìƒì„±"""
    
    slots = state.get("active_task").slots if state.get("active_task") and state.get("active_task").slots else PromotionSlots()
    
    # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¤€ë¹„
    promotion_context = {
        "target_type": getattr(slots, 'target_type', None) or "ë¯¸ì •",
        "brand": getattr(slots, 'brand', None) or "ì—†ìŒ",
        "objective": getattr(slots, 'objective', None) or "ë¯¸ì •", 
        "duration": getattr(slots, 'duration', None) or "ë¯¸ì •",
        "budget": getattr(slots, 'budget', None) or "ë¯¸ì •"
    }
    
    # ìƒìœ„ 20ê°œ ì •ë„ë§Œ LLMì— ì „ë‹¬ (í† í° ì œí•œ ê³ ë ¤)
    top_rows = sorted(rows, key=lambda x: x.get('revenue', 0), reverse=True)[:20]
    
    prompt = f"""ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í˜„ì¬ í”„ë¡œëª¨ì…˜ ê¸°íš ê³¼ì •ì—ì„œ ì‚¬ìš©ìì—ê²Œ ì œì‹œí•  ìƒìœ„ 5ê°œ ì¶”ì²œ ì˜µì…˜ì„ ì„ ë³„í•˜ê³  ê°ê°ì˜ ìƒì„¸í•œ ê·¼ê±°ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

**í˜„ì¬ í”„ë¡œëª¨ì…˜ ê¸°íš ìƒí™©:**
- íƒ€ê²Ÿ ìœ í˜•: {promotion_context['target_type']}
- ì§€ì • ë¸Œëœë“œ: {promotion_context['brand']}  
- ëª©í‘œ: {promotion_context['objective']}
- ê¸°ê°„: {promotion_context['duration']}
- ì˜ˆì‚°: {promotion_context['budget']}

**ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ê²°ê³¼ (ìƒìœ„ 20ê°œ):**
{json.dumps(top_rows, ensure_ascii=False, indent=2)}

**ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„:**
- íŠ¸ë Œë”© í‚¤ì›Œë“œ: {knowledge.get('trending_terms', [])}
- ê³„ì ˆì„± ìŠ¤íŒŒì´í¬: {knowledge.get('seasonal_spikes', [])}
- ìˆ˜ì§‘ ì†ŒìŠ¤: {knowledge.get('notes', [])}

**ìš”ì²­ì‚¬í•­:**
1. ìœ„ ë°ì´í„°ë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬ ìƒìœ„ 5ê°œ ì¶”ì²œì„ ì„ ë³„í•˜ì„¸ìš”
2. ê° ì¶”ì²œë§ˆë‹¤ ë‹¤ìŒ í˜•íƒœë¡œ ìƒì„¸í•œ ê·¼ê±°ë¥¼ 1-3ê°œ ì œì‹œí•˜ì„¸ìš”:
   - "ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ê²°ê³¼..."ë¡œ ì‹œì‘í•˜ëŠ” DB ê·¼ê±° (í•´ë‹¹ì‹œ)
   - "ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼..."ë¡œ ì‹œì‘í•˜ëŠ” ì™¸ë¶€ íŠ¸ë Œë“œ ê·¼ê±° (í•´ë‹¹ì‹œ)
   - í˜„ì¬ í”„ë¡œëª¨ì…˜ ëª©í‘œì™€ì˜ ì—°ê´€ì„± (í•´ë‹¹ì‹œ)
3. ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œ ë§ˆì¼€í„°ê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”

ë‹¤ìŒ JSON í˜•íƒœë¡œ ì •í™•íˆ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "recommendations": [
    {{
      "rank": 1,
      "name": "ìƒí’ˆ/ë¸Œëœë“œëª…",
      "type": "brand" ë˜ëŠ” "product" ë˜ëŠ” "category",
      "id": "ì›ë³¸ ë°ì´í„°ì˜ ì‹ë³„ì",
      "reasons": [
        "ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ê²°ê³¼ êµ¬ì²´ì ì¸ ê·¼ê±°1",
        "ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼ êµ¬ì²´ì ì¸ ê·¼ê±°2",
        "ì¶”ê°€ ë¹„ì¦ˆë‹ˆìŠ¤ ê·¼ê±°3"
      ],
      "metrics_summary": "ì£¼ìš” ì„±ê³¼ ì§€í‘œ ìš”ì•½"
    }}
  ]
}}"""

    from langchain_google_genai import ChatGoogleGenerativeAI
    from langchain_core.output_parsers.json import JsonOutputParser
    
    logger.info("ğŸ¤– LLM ê¸°ë°˜ ì¶”ì²œ ìƒì„± ì‹œì‘...")
    logger.info("ğŸ“Š ì…ë ¥ ë°ì´í„°: %dê°œ í–‰, íŠ¸ë Œë”© ìš©ì–´: %s", len(top_rows), knowledge.get('trending_terms', []))
    
    try:
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash",
            temperature=0.1,
            model_kwargs={"response_format": {"type": "json_object"}},
            api_key=settings.GOOGLE_API_KEY
        )
        
        response = llm.invoke(prompt)
        logger.info("âœ… LLM ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ")
        
        # JSON íŒŒì‹±
        try:
            result = json.loads(response.content)
            recommendations = result.get("recommendations", [])
            
            logger.info("ğŸ“‹ LLM ì¶”ì²œ ê²°ê³¼:")
            for i, rec in enumerate(recommendations):
                logger.info("  %d. %s (%s)", i+1, rec.get("name"), rec.get("type"))
                logger.info("     ê·¼ê±°: %s", rec.get("reasons", [])[:2])
            
            return recommendations
            
        except json.JSONDecodeError as e:
            logger.error("âŒ LLM ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: %s", e)
            logger.error("ì‘ë‹µ ë‚´ìš©: %s", response.content[:500])
            return []
            
    except Exception as e:
        logger.error("âŒ LLM í˜¸ì¶œ ì‹¤íŒ¨: %s", e)
        return []

def _merge_slots(state: OrchestratorState, updates: Dict[str, Any]) -> PromotionSlots:
    current = (state.get("active_task").slots if state.get("active_task") and state.get("active_task").slots else PromotionSlots())
    base = current.model_dump()
    for k, v in updates.items():
        if v not in (None, "", []):
            base[k] = v
    merged = PromotionSlots(**base)
    if state.get("active_task"):
        state["active_task"].slots = merged
    return merged

def slot_extractor_node(state: OrchestratorState):
    logger.info("--- ğŸ” ìŠ¬ë¡¯ ì¶”ì¶œ/ì €ì¥ ë…¸ë“œ ì‹¤í–‰ ---")
    user_message = state.get("user_message", "")
    chat_id = state["chat_id"]

    parser = PydanticOutputParser(pydantic_object=PromotionSlotUpdate)
    prompt_tmpl = textwrap.dedent("""
    ì•„ë˜ í•œêµ­ì–´ ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ **í”„ë¡œëª¨ì…˜ ìŠ¬ë¡¯ ê°’**ì„ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.
    - ì¡´ì¬í•˜ëŠ” ê°’ë§Œ ì±„ìš°ê³ , ì—†ìœ¼ë©´ nullë¡œ ë‘ì„¸ìš”.
    - target_typeì€ "brand" ë˜ëŠ” "category" ì¤‘ í•˜ë‚˜ë¡œë§Œ.
    - ë‚ ì§œ/ê¸°ê°„ì€ ì›ë¬¸ ê·¸ëŒ€ë¡œ ë¬¸ìì—´ë¡œ ìœ ì§€.
    - ì¶œë ¥ì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¥´ì„¸ìš”:
      {format_instructions}

    [ì‚¬ìš©ì ë©”ì‹œì§€]
    {user_message}
    """)
    prompt = ChatPromptTemplate.from_template(
        prompt_tmpl,
        partial_variables={"format_instructions": parser.get_format_instructions()}
    )
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0,
        model_kwargs={"response_format": {"type": "json_object"}},
        api_key=settings.GOOGLE_API_KEY
    )
    parsed: PromotionSlotUpdate = (prompt | llm | parser).invoke({"user_message": user_message})

    updates = {k: v for k, v in parsed.model_dump().items() if v not in (None, "", [])}
    if not updates:
        logger.info("ìŠ¬ë¡¯ ì—…ë°ì´íŠ¸ ì—†ìŒ")
        return {}

    try:
        update_state(chat_id, updates)
        logger.info("Mongo ìƒíƒœ ì—…ë°ì´íŠ¸: %s", updates)
    except Exception as e:
        logger.error("Mongo ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: %s", e)

    merged = _merge_slots(state, updates)
    logger.info("State ìŠ¬ë¡¯ ë³‘í•©: %s", merged.model_dump())
    return {"tool_results": {"slot_updates": updates}}

def _planner_router(state: OrchestratorState) -> str:
    instr = state.get("instructions")
    if not instr:
        return "tool_executor"
        
    resp = (instr.response_generator_instruction or "").strip()
    if resp.startswith("[PROMOTION]"):
        return "slot_extractor"
        
    if instr.tool_calls and len(instr.tool_calls) > 0:
        return "tool_executor"
        
    return "response_generator"

def planner_node(state: OrchestratorState):
    logger.info("--- ğŸ¤” ê³„íš ìˆ˜ë¦½ ë…¸ë“œ ì‹¤í–‰ ---")

    parser = PydanticOutputParser(pydantic_object=OrchestratorInstruction)
    history_summary = summarize_history(state.get("history", []))
    active_task_dump = state['active_task'].model_dump_json() if state.get('active_task') else 'null'
    schema_sig = state.get("schema_info", "")
    today = today_kr()

    prompt_template = textwrap.dedent("""
    You are the orchestrator for a marketing agent. Decide what to do this turn using ONLY the provided context.
    You MUST output a JSON that strictly follows: {format_instructions}

    ## Route decision (VERY IMPORTANT)
    - Decide the user's intent as one of:
      - Promotion flow (create/continue a promotion)
      - One-off answer (DB facts via t2s, or knowledge snippet)
      - Out-of-scope guidance
    - If and only if it is **promotion flow**, prefix `response_generator_instruction` with "[PROMOTION]".
    - If it is **out-of-scope guidance**, prefix with "[OUT_OF_SCOPE]".
    - Otherwise (one-off answer), no prefix.

    ## Tools
    - ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ í•„ìš”í•œ ëª¨ë“  ë„êµ¬ë¥¼ **tool_calls JSON ë°°ì—´**ì— ë‹´ì•„ ìš”ì²­í•˜ì„¸ìš”.
    - í•„ìš”í•˜ë‹¤ë©´ **ì—¬ëŸ¬ ê°œì˜ ë„êµ¬ë¥¼ í•˜ë‚˜ì˜ ë°°ì—´ì— ë™ì‹œì— ìš”ì²­**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ê° ë„êµ¬ ê°ì²´ëŠ” `{{"tool": "ë„êµ¬ëª…", "args": {{"íŒŒë¼ë¯¸í„°ëª…": "ê°’"}}}}` í˜•ì‹ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.
    - ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ê³¼ í˜•ì‹:
      - DB ì¡°íšŒ: `{{"tool": "t2s", "args": {{"instruction": "SQLë¡œ ë³€í™˜í•  ìì—°ì–´ ì§ˆë¬¸", "output_type": "export|visualize|table"}}}}`
        - output_type ì„ íƒ ê°€ì´ë“œë¼ì¸:
          * "export": ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•´ì•¼ í•˜ëŠ” ê²½ìš° (ì˜ˆì‹œ: "í´ë¦­ìœ¨ì´ ê°ì†Œ ì¤‘ì¸ ìœ ì € ID ëª©ë¡", "ì´ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•´ì¤˜", "ë¦¬ìŠ¤íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ì‹¶ì–´")
          * "visualize": ë°ì´í„° ì‹œê°í™”ê°€ í•„ìš”í•œ ê²½ìš° (ì˜ˆì‹œ: "ë¹„êµ"ë¥¼ í•´ì•¼í•˜ëŠ” ì§ˆë¬¸, "ìƒìœ„ 10ê°œ ë¸Œëœë“œ ì•Œë ¤ì¤˜", "ì¶”ì„¸"ì— ëŒ€í•œ ì§ˆë¬¸, "ì‹œê°í™”í•´ì„œ ë³´ì—¬ì¤˜", "ì°¨íŠ¸ë¡œ ë¶„ì„í•´ì¤˜", "ê·¸ë˜í”„ë¡œ ë¹„êµí•´ì¤˜")
          * "table": ë‹¨ìˆœ íŒ©íŠ¸ í™•ì¸ì´ë‚˜ í‘œ í˜•íƒœë¡œ ë³´ê¸° ì›í•˜ëŠ” ê²½ìš° (ì˜ˆ: "ì‘ë…„ ë§¤ì¶œì´ ì–¼ë§ˆì˜€ì§€?", "ë°ì´í„°ë¥¼ í‘œë¡œ ë³´ì—¬ì¤˜")
      - ì›¹ ê²€ìƒ‰: `{{"tool": "tavily_search", "args": {{"query": "ê²€ìƒ‰ì–´", "max_results": 5}}}}`
      - ì›¹ ìŠ¤í¬ë˜í•‘: `{{"tool": "scrape_webpages", "args": {{"urls": ["https://...", ...]}}}}`
      - ë§ˆì¼€íŒ… íŠ¸ë Œë“œ: `{{"tool": "marketing_trend_search", "args": {{"question": "ì§ˆë¬¸"}}}}`
      - ë·°í‹° íŠ¸ë Œë“œ: `{{"tool": "beauty_youtuber_trend_search", "args": {{"question": "ì§ˆë¬¸"}}}}`
    - ë„êµ¬ ì‚¬ìš©ì´ í•„ìš” ì—†ìœ¼ë©´ `tool_calls` í•„ë“œë¥¼ nullë¡œ ë‘ì„¸ìš”.

    ## Time normalization
    - Convert relative dates to ABSOLUTE ranges with Asia/Seoul timezone. Today is {today}.

    ## DB schema signature (hint only):
    {schema_sig}

    ## Conversation summary (last turns):
    {history_summary}

    ## Active task snapshot (JSON or null):
    {active_task}

    ## Decision rules
    - Promotion flow: do NOT call tools this turn. Just set `response_generator_instruction` (with [PROMOTION]).
    - One-off answers: set `tool_calls` as needed.
    - Out-of-scope: both tools null, and provide short polite guidance with [OUT_OF_SCOPE].
    - Output must be concise, Korean polite style.
    
    ## t2s output_type ì„ íƒ ì˜ˆì‹œ
    - "export" ì„ íƒ ì‹œë‚˜ë¦¬ì˜¤:
      * "ìœ ì € ID ëª©ë¡ì„ ì—‘ì…€ë¡œ ë‚´ë ¤ì¤˜" â†’ output_type: "export"
      * "ì´ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•´ì¤˜" â†’ output_type: "export"  
      * "ë¦¬ìŠ¤íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ì‹¶ì–´" â†’ output_type: "export"
      * "ì „ì²´ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ë°›ê³  ì‹¶ì–´" â†’ output_type: "export"
    - "visualize" ì„ íƒ ì‹œë‚˜ë¦¬ì˜¤:
      * "ì¶”ì„¸ë¥¼ ê·¸ë˜í”„ë¡œ ë³´ì—¬ì¤˜" â†’ output_type: "visualize"
      * "ì‹œê°í™”í•´ì„œ ë³´ì—¬ì¤˜" â†’ output_type: "visualize"
      * "ì°¨íŠ¸ë¡œ ë¶„ì„í•´ì¤˜" â†’ output_type: "visualize"
      * "ê·¸ë˜í”„ë¡œ ë¹„êµí•´ì¤˜" â†’ output_type: "visualize"
      * "íŠ¸ë Œë“œë¥¼ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì¤˜" â†’ output_type: "visualize"
    - "table" ì„ íƒ ì‹œë‚˜ë¦¬ì˜¤:
      * "ì‘ë…„ ë§¤ì¶œì´ ì–¼ë§ˆì˜€ì§€?" â†’ output_type: "table"
      * "ìƒìœ„ 10ê°œ ë¸Œëœë“œ ì•Œë ¤ì¤˜" â†’ output_type: "table"
      * "ë°ì´í„°ë¥¼ í‘œë¡œ ë³´ì—¬ì¤˜" â†’ output_type: "table"
      * "ë§¤ì¶œ ìˆœìœ„ë¥¼ ì•Œë ¤ì¤˜" â†’ output_type: "table"
      * "ì–´ë–¤ ë¸Œëœë“œê°€ ì œì¼ ì˜ íŒ”ë ¸ì–´?" â†’ output_type: "table"

    User Message: "{user_message}"
    """)

    prompt = ChatPromptTemplate.from_template(
        template=prompt_template,
        partial_variables={"format_instructions": parser.get_format_instructions()}
    )
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0,
        model_kwargs={"response_format": {"type": "json_object"}},
        api_key=settings.GOOGLE_API_KEY
    )

    instructions = (prompt | llm | parser).invoke({
        "user_message": state['user_message'],
        "history_summary": history_summary,
        "active_task": active_task_dump,
        "schema_sig": schema_sig,
        "today": today,
    })

    return {"instructions": instructions}

def action_state_node(state: OrchestratorState):
    logger.info("--- ğŸ“‹ ì•¡ì…˜ ìƒíƒœ í™•ì¸ ë…¸ë“œ ì‹¤í–‰ ---")
    slots = state.get("active_task").slots if state.get("active_task") and state.get("active_task").slots else None
    decision = get_action_state(slots=slots)
    logger.info("Action decision: %s", decision)
    return {"tool_results": {"action": decision}}

def _action_router(state: OrchestratorState) -> str:
    """
    action_state ê²°ê³¼ë¡œ ë‹¤ìŒ ë…¸ë“œ ê²°ì •:
    - brand/targetì„ ë¬»ê±°ë‚˜, íŠ¹ì • productë¥¼ ë¬¼ì–´ì•¼ í•˜ëŠ” ìƒí™©ì´ë©´ options_generatorë¡œ ë¶„ê¸°
    - ê·¸ ì™¸ (objective/duration ì§ˆë¬¸, ìµœì¢… í™•ì¸ ë“±)ëŠ” response_generatorë¡œ ë¶„ê¸°
    """
    tr = state.get("tool_results") or {}
    action = tr.get("action") or {}
    status = action.get("status")
    missing = action.get("missing_slots", [])

    # --- ğŸ‘‡ ì—¬ê¸°ê°€ í•µì‹¬ì ì¸ ë³€ê²½ ë¶€ë¶„ì…ë‹ˆë‹¤ ---
    # 'ask_for_product' ìƒíƒœì¼ ë•Œ options_generatorë¥¼ í˜¸ì¶œí•˜ë„ë¡ ëª…ì‹œ
    if status == "ask_for_product":
        return "options_generator"
    # ------------------------------------
    
    # ê¸°ì¡´ ë¡œì§: brandë‚˜ targetì„ ë¬¼ì–´ì•¼ í•  ë•Œë„ options_generator í˜¸ì¶œ
    if status == "ask_for_slots" and any(m in ("brand", "target") for m in missing):
        return "options_generator"
        
    return "response_generator"
    
def _build_candidate_t2s_instruction(target_type: str, slots: PromotionSlots) -> str:
    end = datetime.now(ZoneInfo("Asia/Seoul")).date()
    start = end - timedelta(days=60)
    
    # --- ğŸ‘‡ ì—¬ê¸°ê°€ í•µì‹¬ì ì¸ ë³€ê²½ ë¶€ë¶„ì…ë‹ˆë‹¤ ---
    # ë¸Œëœë“œ í•„í„°ë§ ì¡°ê±´ì„ ë‹´ì„ ë³€ìˆ˜
    brand_filter_instruction = ""
    # slotsì— brand ì •ë³´ê°€ ìˆìœ¼ë©´ í•„í„°ë§ ì§€ì‹œë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    if slots and slots.brand:
        brand_filter_instruction = f" ë˜í•œ, ê²°ê³¼ëŠ” ë°˜ë“œì‹œ '{slots.brand}' ë¸Œëœë“œì˜ ì œí’ˆë§Œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤."
    # ------------------------------------
 
    if target_type == "brand":
        return textwrap.dedent(f"""
        ìµœê·¼ ê¸°ê°„ {start}~{end}ì™€ ì§ì „ ë™ì¼ ê¸°ê°„ì„ ë¹„êµí•˜ì—¬ ë¸Œëœë“œ ë ˆë²¨ í›„ë³´ ëª©ë¡ì„ ì‚°ì¶œí•´ ì£¼ì„¸ìš”.{brand_filter_instruction}
        ë°˜ë“œì‹œ ë‹¤ìŒ ì»¬ëŸ¼ aliasë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
        - brand_name
        - revenue (ìµœê·¼ ê¸°ê°„ ë§¤ì¶œ)
        - growth_pct (ì´ì „ ë™ì¼ê¸°ê°„ ëŒ€ë¹„ ì¦ê°ìœ¨, %)
        - gm (ìµœê·¼ ê¸°ê°„ ì´ì´ìµë¥ , 0~1)
        - conversion_rate
        - repeat_rate
        - aov
        - inventory_days
        - return_rate
        - category_name
        - price_band
        - gender_age
        í–‰ì€ ë¸Œëœë“œë³„ 1í–‰ì…ë‹ˆë‹¤. ìµœê·¼ ê¸°ê°„ ë§¤ì¶œ ìƒìœ„ 100ê°œ ë‚´ì—ì„œ ë°˜í™˜í•´ ì£¼ì„¸ìš”.
        """).strip()
    else:
        return textwrap.dedent(f"""
        ìµœê·¼ ê¸°ê°„ {start}~{end}ì™€ ì§ì „ ë™ì¼ ê¸°ê°„ì„ ë¹„êµí•˜ì—¬ ì¹´í…Œê³ ë¦¬/ìƒí’ˆ ë ˆë²¨ í›„ë³´ ëª©ë¡ì„ ì‚°ì¶œí•´ ì£¼ì„¸ìš”.
        ê°€ëŠ¥í•œ ê²½ìš° ë‹¤ìŒ ì»¬ëŸ¼ aliasë¥¼ í¬í•¨í•˜ì„¸ìš”:
        - product_id
        - product_name
        - category_name
        - revenue
        - growth_pct
        - gm
        - conversion_rate
        - repeat_rate
        - aov
        - inventory_days
        - return_rate
        - price_band
        - gender_age
        í–‰ì€ ìƒí’ˆ(ë˜ëŠ” ì¹´í…Œê³ ë¦¬)ë³„ 1í–‰ì…ë‹ˆë‹¤. ìµœê·¼ ê¸°ê°„ ë§¤ì¶œ ìƒìœ„ 200ê°œ ë‚´ì—ì„œ ë°˜í™˜í•´ ì£¼ì„¸ìš”.
        """).strip()

def options_generator_node(state: OrchestratorState):
    logger.info("--- ğŸ§  ì˜µì…˜ ì œì•ˆ ë…¸ë“œ ì‹¤í–‰ ì‹œì‘ ---")
    logger.info("ğŸ“Š ì…ë ¥ ìƒíƒœ ì •ë³´:")
    logger.info("  - chat_id: %s", state.get("chat_id"))
    logger.info("  - active_task ì¡´ì¬: %s", bool(state.get("active_task")))
    
    chat_id = state["chat_id"]
    slots = state.get("active_task").slots if state.get("active_task") and state.get("active_task").slots else PromotionSlots()
    target_type = slots.target_type or "brand"
    
    logger.info("ğŸ¯ íƒ€ê²Ÿ íƒ€ì…: %s", target_type)
    logger.info("ğŸ“‹ ìŠ¬ë¡¯ ì •ë³´: %s", slots)

    logger.info("ğŸ”§ T2S ì¸ìŠ¤íŠ¸ëŸ­ì…˜ ìƒì„± ì¤‘...")
    t2s_instr = _build_candidate_t2s_instruction(target_type, slots)
    logger.info("ğŸ“ ìƒì„±ëœ T2S ì¸ìŠ¤íŠ¸ëŸ­ì…˜: %s", t2s_instr[:200] + "..." if len(t2s_instr) > 200 else t2s_instr)
    
    logger.info("ğŸš€ T2S ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...")
    table = run_t2s_agent_with_instruction(state, t2s_instr, "visualize")  # ì˜µì…˜ ìƒì„±ì€ í•­ìƒ ì‹œê°í™” í¬í•¨
    rows = table["rows"]
    
    logger.info("ğŸ“Š T2S ê²°ê³¼ ë¶„ì„:")
    logger.info("  - ì „ì²´ í–‰ ìˆ˜: %d", len(rows))
    logger.info("  - ì»¬ëŸ¼ ì •ë³´: %s", list(table.get("columns", [])))
    
    if rows:
        logger.info("ğŸ“‹ ì²« ë²ˆì§¸ í–‰ ìƒ˜í”Œ: %s", {k: v for k, v in rows[0].items() if k in ['brand_name', 'product_name', 'category_name', 'revenue', 'growth_pct']})

    if not rows:
        logger.warning("âŒ T2S í›„ë³´ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        logger.info("ğŸ”„ ë¹ˆ ê²°ê³¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ ì¤‘...")
        update_state(chat_id, {"product_options": []})
        tr = state.get("tool_results") or {}
        tr["option_candidates"] = {"candidates": [], "method": "deterministic_v1", "time_window": "", "constraints": {}}
        logger.info("âœ… ë¹ˆ ì˜µì…˜ í›„ë³´ ë°˜í™˜ ì™„ë£Œ")
        return {"tool_results": tr}

    logger.info("ğŸ” ì§€ì‹ ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘ ì¤‘...")
    knowledge = get_knowledge_snapshot()
    trending_terms = knowledge.get("trending_terms", [])
    
    logger.info("ğŸ“ˆ íŠ¸ë Œë”© ìš©ì–´ ë¶„ì„:")
    logger.info("  - íŠ¸ë Œë”© ìš©ì–´ ìˆ˜: %d", len(trending_terms))
    logger.info("  - íŠ¸ë Œë”© ìš©ì–´ ëª©ë¡: %s", trending_terms)
    logger.info("  - ê³„ì ˆì„± ìŠ¤íŒŒì´í¬: %s", knowledge.get("seasonal_spikes", []))
    logger.info("  - ìˆ˜ì§‘ ë…¸íŠ¸: %s", knowledge.get("notes", []))

    logger.info("ğŸ¤– LLM ê¸°ë°˜ ì¶”ì²œ ìƒì„± ì¤‘...")
    llm_recommendations = _generate_llm_recommendations(state, rows, knowledge)
    
    if not llm_recommendations:
        logger.warning("âŒ LLM ì¶”ì²œ ìƒì„± ì‹¤íŒ¨ - ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±")
        # í´ë°±: ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
        enriched = compute_opportunity_score(rows, trending_terms)
        topk = pick_diverse_top_k(enriched, k=5)
        
        labels = []
        candidates = []
        for i, r in enumerate(topk):
            if target_type == "brand":
                cid = f"brand:{r.get('brand_name')}"
                label = str(r.get("brand_name") or "ì•Œ ìˆ˜ ì—†ëŠ” ë¸Œëœë“œ")
                typ = "brand"
            else:
                name = r.get("product_name") or r.get("category_name") or "ì•Œ ìˆ˜ ì—†ëŠ” í•­ëª©"
                cid = f"product:{r.get('product_id') or name}"
                label = str(name)
                typ = "product" if r.get("product_name") else "category"
            
            labels.append(label)
            candidates.append({
                "id": cid,
                "label": label,
                "type": typ,
                "metrics": {k: r.get(k) for k in ("revenue","growth_pct","gm","conversion_rate","repeat_rate","aov","inventory_days","seasonality_score","return_rate") if k in r},
                "opportunity_score": r.get("opportunity_score"),
                "reasons": r.get("reasons", []),
                "diversity_tags": [x for x in (r.get("category_name"), r.get("price_band"), r.get("gender_age")) if x],
            })
    else:
        logger.info("âœ… LLM ì¶”ì²œ ìƒì„± ì„±ê³µ - %dê°œ ì¶”ì²œ", len(llm_recommendations))
        
        labels = []
        candidates = []
        
        for i, rec in enumerate(llm_recommendations[:5]):  # ìµœëŒ€ 5ê°œ
            # LLM ì¶”ì²œì„ í‘œì¤€ í›„ë³´ í˜•íƒœë¡œ ë³€í™˜
            name = rec.get("name", f"ì¶”ì²œ{i+1}")
            typ = rec.get("type", "product")
            
            # ì›ë³¸ ë°ì´í„°ì—ì„œ í•´ë‹¹ í•­ëª© ì°¾ê¸° (ë©”íŠ¸ë¦­ ì •ë³´ë¥¼ ìœ„í•´)
            original_row = None
            for row in rows:
                if (row.get("brand_name") == name or 
                    row.get("product_name") == name or 
                    row.get("category_name") == name):
                    original_row = row
                    break
            
            if target_type == "brand":
                cid = f"brand:{name}"
            else:
                cid = f"product:{rec.get('id', name)}"
            
            labels.append(name)
            
            candidate = {
                "id": cid,
                "label": name,
                "type": typ,
                "llm_reasons": rec.get("reasons", []),  # LLMì´ ìƒì„±í•œ ìƒì„¸ ì„¤ëª…
                "metrics_summary": rec.get("metrics_summary", ""),
                "rank": rec.get("rank", i+1),
                "metrics": {k: original_row.get(k) for k in ("revenue","growth_pct","gm","conversion_rate","repeat_rate","aov","inventory_days","seasonality_score","return_rate") if original_row and k in original_row} if original_row else {},
            }
            
            candidates.append(candidate)
            
            logger.info("  %dë²ˆ LLM ì¶”ì²œ: %s (%s)", i+1, name, typ)
            logger.info("    - ê·¼ê±° ê°œìˆ˜: %d", len(rec.get("reasons", [])))
            logger.info("    - ë©”íŠ¸ë¦­ ìš”ì•½: %s", rec.get("metrics_summary", "ì—†ìŒ")[:100])

    option_json = {
        "candidates": candidates,
        "method": "deterministic_v1",
        "time_window": "",
        "constraints": {"min_gm": 0.25, "max_return_rate": 0.1},
    }

    logger.info("ğŸ’¾ ìƒíƒœ ì—…ë°ì´íŠ¸ ì¤‘...")
    try:
        update_state(chat_id, {"product_options": labels})
        logger.info("âœ… ì˜µì…˜ ë¼ë²¨ ìƒíƒœ ì €ì¥ ì„±ê³µ")
    except Exception as e:
        logger.error("âŒ ì˜µì…˜ ë¼ë²¨ ì €ì¥ ì‹¤íŒ¨: %s", e)

    logger.info("ğŸ”„ ìŠ¬ë¡¯ ë³‘í•© ì¤‘...")
    merged_slots = _merge_slots(state, {"product_options": labels})
    logger.info("âœ… ì˜µì…˜ ë¼ë²¨ state ë°˜ì˜: %s", merged_slots.product_options)

    logger.info("ğŸ“¤ ìµœì¢… ê²°ê³¼ ë°˜í™˜ ì¤€ë¹„ ì¤‘...")
    tr = state.get("tool_results") or {}
    tr["option_candidates"] = option_json
    
    logger.info("ğŸ‰ ì˜µì…˜ ì œì•ˆ ë…¸ë“œ ì‹¤í–‰ ì™„ë£Œ!")
    logger.info("ğŸ“Š ìµœì¢… ê²°ê³¼ ìš”ì•½:")
    logger.info("  - í›„ë³´ ìˆ˜: %d", len(candidates))
    logger.info("  - ë¼ë²¨ ëª©ë¡: %s", labels)
    logger.info("  - ì œì•½ ì¡°ê±´: %s", option_json["constraints"])
    
    return {"tool_results": tr}

def _parse_knowledge_calls(instr: Optional[Union[str, List[Dict[str, Any]], Dict[str, Any]]]) -> List[Dict[str, Any]]:
    if instr is None:
        return []

    if isinstance(instr, dict):
        return [instr]

    if isinstance(instr, list):
        # ensure list of dicts
        return [c for c in instr if isinstance(c, dict)]

    if isinstance(instr, str):
        try:
            data = json.loads(instr)
            if isinstance(data, dict):
                return [data]
            if isinstance(data, list):
                return [c for c in data if isinstance(c, dict)]
            return []
        except Exception:

            return []
    return []


def tool_executor_node(state: OrchestratorState):
    logger.info("--- ğŸ”¨ íˆ´ ì‹¤í–‰ ë…¸ë“œ ì‹¤í–‰ ---")
    instructions = state.get("instructions")
    tool_calls = instructions.tool_calls if instructions and instructions.tool_calls else []

    if not tool_calls:
        logger.info("ì‹¤í–‰í•  íˆ´ì´ ì—†ìŠµë‹ˆë‹¤.")
        return {"tool_results": None}

    tool_map = {
        "t2s": lambda args: run_t2s_agent_with_instruction(state, args.get("instruction", ""), args.get("output_type", "table")),
        "tavily_search": lambda args: run_tavily_search(args.get("query", ""), args.get("max_results", 5)),
        "scrape_webpages": lambda args: scrape_webpages(args.get("urls", [])),
        "marketing_trend_search": lambda args: marketing_trend_search(args.get("question", "")),
        "beauty_youtuber_trend_search": lambda args: beauty_youtuber_trend_search(args.get("question", "")),
    }
    
    tool_results = {}

    with ThreadPoolExecutor(max_workers=len(tool_calls)) as executor:
        future_to_call = {}
        for i, call in enumerate(tool_calls):
            tool_name = call.get("tool")
            tool_args = call.get("args", {})

            logger.info(f"ğŸ§© {tool_name} ì‹¤í–‰")
            
            if tool_name in tool_map:
                result_key = f"{tool_name}_{i}"
                future = executor.submit(tool_map[tool_name], tool_args)
                future_to_call[future] = result_key
            else:
                logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬ '{tool_name}' í˜¸ì¶œì€ ê±´ë„ˆëœë‹ˆë‹¤.")
        
        for future in future_to_call:
            result_key = future_to_call[future]

            try:
                result = future.result()
                tool_results[result_key] = result

            except Exception as e:
                logger.error(f"'{result_key}' íˆ´ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                tool_results[result_key] = {"error": str(e)}


    existing_results = state.get("tool_results") or {}
    merged_results = {**existing_results, **tool_results}
    
    return {"tool_results": merged_results}

def _should_visualize_router(state: OrchestratorState) -> str:
    tool_results = state.get("tool_results", {})
    # tool_results ì•ˆì— t2së¡œ ì‹œì‘í•˜ê³  ë°ì´í„°ê°€ ìˆëŠ” ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
    for key, value in tool_results.items():
        if key.startswith("t2s") and value and value.get("rows"):
            output_type = value.get("output_type", "table")
            logger.info(f"T2S ê²°ê³¼ê°€ ìˆê³  output_typeì´ '{output_type}'ì…ë‹ˆë‹¤.")
            
            # output_typeì— ë”°ë¼ ì‹œê°í™” ì—¬ë¶€ ê²°ì •
            if output_type == "visualize":
                logger.info("ì‹œê°í™”ë¥¼ ì‹œë„í•©ë‹ˆë‹¤.")
                return "visualize"
            elif output_type == "table":
                logger.info("í‘œë§Œ í‘œì‹œí•˜ë¯€ë¡œ ì‹œê°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                return "skip_visualize"
            elif output_type == "export":
                logger.info("íŒŒì¼ ë‚´ë³´ë‚´ê¸°ì´ë¯€ë¡œ ì‹œê°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                return "skip_visualize"
            else:
                logger.info("ê¸°ë³¸ê°’ìœ¼ë¡œ í‘œë§Œ í‘œì‹œí•©ë‹ˆë‹¤.")
                return "skip_visualize"
            
    logger.info("T2S ê²°ê³¼ê°€ ì—†ì–´ ì‹œê°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
    return "skip_visualize"

def visualizer_caller_node(state: OrchestratorState):
    logger.info("--- ğŸ“Š ì‹œê°í™” ë…¸ë“œ ì‹¤í–‰ ---")
    
    # t2s ê²°ê³¼ë¥¼ ì°¾ìŠµë‹ˆë‹¤. ì—¬ëŸ¬ tool_results ì¤‘ t2s_0, t2s_1 ë“±ì„ ì°¾ë„ë¡ ìˆ˜ì •
    t2s_result = None
    tool_results = state.get("tool_results", {})
    for key, value in tool_results.items():
        if key.startswith("t2s") and value and value.get("rows"):
            t2s_result = value
            break
    
    if not t2s_result:
        logger.info("ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
        return {}

    # Visualizer ê·¸ë˜í”„ ì‹¤í–‰
    visualizer_app = build_visualize_graph(model="gemini-2.5-flash") # ëª¨ë¸ëª…ì€ ì„¤ì •ì— ë”°ë¼ ë³€ê²½
    viz_state = VisualizeState(
        user_question=state.get("user_message"),
        instruction="ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ì•„ë˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì ì˜ ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ê³  ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        json_data=json.dumps(t2s_result, ensure_ascii=False)
    )
    
    viz_response = visualizer_app.invoke(viz_state)

    # ì‹œê°í™” ê²°ê³¼ë¥¼ tool_resultsì— ì¶”ê°€
    if viz_response:
        tool_results["visualization"] = {
            "json_graph": viz_response.get("json_graph"),
            "explanation": viz_response.get("output")
        }
        
    return {"tool_results": tool_results}

def response_generator_node(state: OrchestratorState):
    logger.info("--- ğŸ—£ï¸ ì‘ë‹µ ìƒì„± ë…¸ë“œ ---")
    instructions = state.get("instructions")
    tr = state.get("tool_results") or {}

    instructions_text = (
        instructions.response_generator_instruction
        if instructions and instructions.response_generator_instruction
        else "ì‚¬ìš©ì ìš”ì²­ì— ë§ì¶° ì •ì¤‘í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”."
    )

    t2s_table = None
    t2s_output_type = "table"  # ê¸°ë³¸ê°’
    t2s_download_url = None
    web_search = None
    scraped_pages = None
    marketing_trend_results = None
    youtuber_trend_results = None
    for key, value in tr.items():
        if key.startswith("t2s") and isinstance(value, dict) and "rows" in value:
            t2s_table = value
            t2s_output_type = value.get("output_type", "table")
            t2s_download_url = value.get("download_url")
        elif key.startswith("tavily_search"): 
            web_search = value
        elif key.startswith("scrape_webpages"):
            scraped_pages = value
        elif key.startswith("marketing_trend_search"):
            marketing_trend_results = value
        elif key.startswith("beauty_youtuber_trend_search"):
            youtuber_trend_results = value

    action_decision = tr.get("action")
    knowledge_snippet = tr.get("knowledge") if isinstance(tr.get("knowledge"), str) else None
    option_candidates = tr.get("option_candidates") if isinstance(tr.get("option_candidates"), dict) else None

    prompt_tmpl = textwrap.dedent("""
    ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì˜ ìµœì¢… ì‘ë‹µ ìƒì„±ê¸°ì…ë‹ˆë‹¤.
    ì•„ë˜ ì…ë ¥ë§Œì„ ê·¼ê±°ë¡œ **í•œêµ­ì–´ ì¡´ëŒ“ë§**ë¡œ í•œ ë²ˆì— ì™„ì„±ëœ ë‹µë³€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.
    ë‚´ë¶€ ë„êµ¬ëª…ì´ë‚˜ ì‹œìŠ¤í…œ ì„¸ë¶€ êµ¬í˜„ì€ ì–¸ê¸‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

    [ì…ë ¥ ì„¤ëª…]
    - instructions_text: ì´ë²ˆ í„´ì˜ í†¤/ë°©í–¥.
    - action_decision: í”„ë¡œëª¨ì…˜ ì˜ì‚¬ê²°ì •(JSON).
    - option_candidates: ìœ ì €ì—ê²Œ ì œì•ˆí•  í›„ë³´ ëª©ë¡(JSON).
    - t2s_table: DB ì§ˆì˜ ê²°ê³¼(JSON). ìˆìœ¼ë©´ ìƒìœ„ 10í–‰ë§Œ í‘œë¡œ ë¯¸ë¦¬ë³´ê¸°.
    - knowledge_snippet: ê°„ë‹¨ ì°¸ê³ (ì„ íƒ).
    - web_search: ì›¹ ê²€ìƒ‰ ê²°ê³¼(JSON: results[title,url,content]).
    - scraped_pages: ì›¹ í˜ì´ì§€ ë³¸ë¬¸ ìŠ¤í¬ë˜í•‘ ê²°ê³¼(JSON: documents[source,content]).
    - marketing_trend_results: Supabase ë§ˆì¼€íŒ… íŠ¸ë Œë“œ ê²°ê³¼(JSON).
    - youtuber_trend_results: Supabase ë·°í‹° ìœ íŠœë²„ íŠ¸ë Œë“œ ê²°ê³¼(JSON).

    [ì‘ì„± ì§€ì¹¨]
    1) **ê°€ì¥ ì¤‘ìš”í•œ ê·œì¹™**: `action_decision` ê°ì²´ê°€ ìˆê³ , ê·¸ ì•ˆì˜ `ask_prompts` ë¦¬ìŠ¤íŠ¸ì— ë‚´ìš©ì´ ìˆë‹¤ë©´, ë‹¹ì‹ ì˜ ìµœìš°ì„  ì„ë¬´ëŠ” í•´ë‹¹ ë¦¬ìŠ¤íŠ¸ì˜ ì§ˆë¬¸ì„ ì‚¬ìš©ìì—ê²Œ í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë‹¤ë¥¸ ëª¨ë“  ì§€ì‹œë³´ë‹¤ ì´ ê·œì¹™ì„ **ë°˜ë“œì‹œ** ë”°ë¼ì•¼ í•©ë‹ˆë‹¤. `ask_prompts`ì˜ ë¬¸êµ¬ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê±°ë‚˜, ì‚´ì§ ë” ìì—°ìŠ¤ëŸ½ê²Œë§Œ ë‹¤ë“¬ì–´ ì§ˆë¬¸í•˜ì„¸ìš”. (ì˜ˆ: "íƒ€ê²Ÿ ì¢…ë¥˜ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”. (brand | category)")
    2) ìœ„ 1ë²ˆ ê·œì¹™ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ë§Œ, `instructions_text`ë¥¼ ì£¼ëœ ë‚´ìš©ìœ¼ë¡œ ì‚¼ì•„ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    3) `option_candidates`ê°€ ìˆìœ¼ë©´ ë²ˆí˜¸ë¡œ ì œì‹œí•˜ê³  ê° 2~4ì¤„ ê·¼ê±°ë¥¼ ë¶™ì…ë‹ˆë‹¤. 
       - í›„ë³´ì— `llm_reasons` í•„ë“œê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ìš°ì„  ì‚¬ìš©í•˜ì„¸ìš” (LLMì´ ìƒì„±í•œ ìƒì„¸ ê·¼ê±°)
       - `llm_reasons`ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ `reasons`, `business_reasons` ë“±ì„ ì‚¬ìš©í•˜ì„¸ìš”
       - ëª¨ë“  ìˆ˜ì¹˜ëŠ” ì–´ë–¤ ìˆ˜ì¹˜ì¸ì§€ êµ¬ì²´ì ì¸ ì–¸ê¸‰ì„ í•´ì£¼ì„¸ìš”
       - ë§ˆì§€ë§‰ì— 'ê¸°íƒ€(ì§ì ‘ ì…ë ¥)'ë„ ì¶”ê°€í•©ë‹ˆë‹¤    
    4) web_search / scraped_pages / supabase ê²°ê³¼ê°€ ìˆìœ¼ë©´, í•µì‹¬ ê·¼ê±°ë¥¼ 2~4ì¤„ë¡œ ìš”ì•½í•´ ì„¤ëª…ì— ë…¹ì—¬ ì£¼ì„¸ìš”. ì›ë¬¸ ì¸ìš©ì€ 1~2ë¬¸ì¥ ì´í•˜ë¡œ ì œí•œ.
    5) t2s_table ì²˜ë¦¬ ê·œì¹™:
       - output_typeì´ "export"ì¸ ê²½ìš°: í‘œë‚˜ ì‹œê°í™”ë¥¼ í¬í•¨í•˜ì§€ ë§ê³ , ë°ì´í„° ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŒì„ ì•ˆë‚´í•˜ì„¸ìš”. ë‹¤ìš´ë¡œë“œ ë§í¬ëŠ” ì‹œìŠ¤í…œì—ì„œ ìë™ìœ¼ë¡œ ì¶”ê°€ë©ë‹ˆë‹¤.
       - output_typeì´ "table"ì¸ ê²½ìš°: ìƒìœ„ 10í–‰ ë¯¸ë¦¬ë³´ê¸° í‘œë§Œ í¬í•¨í•˜ë˜, ì—†ëŠ” ìˆ˜ì¹˜ëŠ” ë§Œë“¤ì§€ ë§ˆì„¸ìš”. í‘œë¥¼ ì‹œì‘í•˜ëŠ” ë¶€ë¶„ì€ [TABLE_START] í‘œê°€ ëë‚˜ëŠ” ë¶€ë¶„ì€ [TABLE_END] ë¼ëŠ” í…ìŠ¤íŠ¸ë¥¼ ë¶™ì—¬ì„œ ì–´ë””ë¶€í„° ì–´ë””ê°€ í…Œì´ë¸”ì¸ì§€ ì•Œ ìˆ˜ ìˆê²Œ í•´ì£¼ì„¸ìš”.
       - output_typeì´ "visualize"ì¸ ê²½ìš°: ìƒìœ„ 10í–‰ ë¯¸ë¦¬ë³´ê¸° í‘œë¥¼ í¬í•¨í•˜ê³ , ì‹œê°í™” ê²°ê³¼ê°€ ìˆë‹¤ë©´ í•¨ê»˜ ì œê³µí•˜ì„¸ìš”.
    6) ì „ì²´ì ìœ¼ë¡œ êµ¬ì¡°í™”ëœ í˜•ì‹ì„ ìœ ì§€í•˜ì„¸ìš”.

    [ì…ë ¥ ë°ì´í„°]
    - instructions_text:
    {instructions_text}

    - action_decision (JSON):
    {action_decision_json}

    - option_candidates (JSON):
    {option_candidates_json}

    - t2s_table (JSON):
    {t2s_table_json}

    - t2s_output_type:
    {t2s_output_type}



    - web_search (JSON):
    {web_search_json}

    - scraped_pages (JSON):
    {scraped_pages_json}

    - marketing_trend_results (JSON):
    {marketing_trend_results_json}

    - youtuber_trend_results (JSON):
    {youtuber_trend_results_json}

    - knowledge_snippet:
    {knowledge_snippet}
    """)

    to_json = lambda x: json.dumps(x, ensure_ascii=False) if x is not None else "null"

    prompt = ChatPromptTemplate.from_template(prompt_tmpl)
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0, api_key=settings.GOOGLE_API_KEY)
    # llm = ChatAnthropic(model="claude-3-7-sonnet-20250219", temperature=0, api_key=settings.ANTHROPIC_API_KEY)
    
    final_text = (prompt | llm).invoke({
        "instructions_text": instructions_text,
        "action_decision_json": to_json(action_decision),
        "option_candidates_json": to_json(option_candidates),
        "t2s_table_json": to_json(t2s_table),
        "t2s_output_type": t2s_output_type,

        "web_search_json": to_json(web_search),
        "scraped_pages_json": to_json(scraped_pages),
        "marketing_trend_results_json": to_json(marketing_trend_results),
        "youtuber_trend_results_json": to_json(youtuber_trend_results),
        "knowledge_snippet": knowledge_snippet or "",
    })

    final_response = getattr(final_text, "content", None) or str(final_text)
    
    # export íƒ€ì…ì¼ ë•Œ ë‹¤ìš´ë¡œë“œ ë§í¬ ì¶”ê°€
    if t2s_output_type == "export" and t2s_download_url:
        download_link = f"\n\n[CSV ë‹¤ìš´ë¡œë“œ]({t2s_download_url})"
        final_response += download_link
        logger.info(f"Export ë§í¬ ì¶”ê°€ë¨: {t2s_download_url}")
    elif t2s_output_type == "export" and not t2s_download_url:
        error_message = "\n\nâš ï¸ íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
        final_response += error_message
        logger.warning("Export ìš”ì²­ì´ì§€ë§Œ ë‹¤ìš´ë¡œë“œ URLì´ ì—†ìŠµë‹ˆë‹¤.")
    
    logger.info(f"ìµœì¢… ê²°ê³¼(L):\n{final_response}")
    history = state.get("history", [])
    history.append({"role": "user", "content": state.get("user_message", "")})
    history.append({"role": "assistant", "content": final_response})
    
    # logger.info(f"{state}")
    return {"history": history, "user_message": "", "output": final_response}

# ===== Graph =====
workflow = StateGraph(OrchestratorState)

workflow.add_node("planner", planner_node)
workflow.add_node("slot_extractor", slot_extractor_node)
workflow.add_node("action_state", action_state_node)
workflow.add_node("options_generator", options_generator_node)
workflow.add_node("tool_executor", tool_executor_node)
workflow.add_node("visualizer", visualizer_caller_node) 
workflow.add_node("response_generator", response_generator_node)

workflow.set_entry_point("planner")

workflow.add_conditional_edges(
    "planner",
    _planner_router,
    {
        "slot_extractor": "slot_extractor",
        "tool_executor": "tool_executor",
        "response_generator": "response_generator",
    },
)

workflow.add_edge("slot_extractor", "action_state")
workflow.add_conditional_edges(
    "action_state",
    _action_router,
    {
        "options_generator": "options_generator",
        "response_generator": "response_generator",
    },
)
workflow.add_edge("options_generator", "response_generator")

workflow.add_conditional_edges(
    "tool_executor",
    _should_visualize_router,
    {
        "visualize": "visualizer",
        "skip_visualize": "response_generator"
    }
)
workflow.add_edge("visualizer", "response_generator")
workflow.add_edge("response_generator", END)

orchestrator_app = workflow.compile()