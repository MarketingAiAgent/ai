# app/agents/orchestrator/graph.py
from __future__ import annotations

import json
import textwrap
import logging
import re
from typing import List, Optional, Dict, Any, Literal, TypedDict
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
from zoneinfo import ZoneInfo

from pydantic import BaseModel, Field
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers.pydantic import PydanticOutputParser
from langgraph.graph import StateGraph, END

from langchain_google_genai import ChatGoogleGenerativeAI
from app.core.config import settings
from app.agents.text_to_sql.__init__ import call_sql_generator
from .state import *

logger = logging.getLogger(__name__)


# =========================
# Tools
# =========================

def run_t2s_agent(state: OrchestratorState):
    instruction = state['instructions'].t2s_instruction
    logger.info("T2S ì—ì´ì „íŠ¸ ì‹¤í–‰: %s", instruction)

    result = call_sql_generator(message=instruction, conn_str=state['conn_str'], schema_info=state['schema_info'])
    sql = result['query']
    table = result["data_json"]

    logger.info(f"ì¿¼ë¦¬: \n{sql}")
    logger.info(f"ê²°ê³¼ í…Œì´ë¸”: \n{table}")

    if isinstance(table, str):
        table = json.loads(table)
    return table

def run_knowledge_agent(instruction: str) -> str:
    logger.info("ì§€ì‹ ì—ì´ì „íŠ¸ ì‹¤í–‰: %s", instruction)
    return "ìµœê·¼ ìˆí¼ ì½˜í…ì¸ ë¥¼ í™œìš©í•œ ë°”ì´ëŸ´ ë§ˆì¼€íŒ…ì´ ì¸ê¸°ì…ë‹ˆë‹¤."

# =========================
# Helpers
# =========================

def _summarize_history(history: List[Dict[str, str]], limit_chars: int = 800) -> str:
    """ìµœê·¼ íˆìŠ¤í† ë¦¬ë¥¼ ê°„ë‹¨ ìš”ì•½ìœ¼ë¡œ ì œê³µ (LLM ì»¨í…ìŠ¤íŠ¸ìš©)"""
    text = " ".join(h.get("content", "") for h in history[-6:])
    return text[:limit_chars]

def _today_kr() -> str:
    """Asia/Seoul ê¸°ì¤€ ì˜¤ëŠ˜ ë‚ ì§œ yyyy-mm-dd"""
    try:
        return datetime.now(ZoneInfo("Asia/Seoul")).strftime("%Y-%m-%d")
    except Exception:
        return datetime.now().strftime("%Y-%m-%d")

def _normalize_table(table: Any) -> Dict[str, Any]:
    """
    t2s í‘œ ê²°ê³¼ë¥¼ í‘œì¤€ í˜•íƒœë¡œ ì •ê·œí™”.

    ì§€ì›í•˜ëŠ” ì…ë ¥:
      - {"rows":[...], "columns":[...]}                           # ì´ë¯¸ í‘œì¤€
      - {"columns":[...], "data":[[...], ...]}                    # pandas orient='split'
      - {"schema": {...}, "data":[{...}, ...]}                    # pandas orient='table'
      - [{"col": val, ...}, ...]                                  # pandas orient='records'
      - {col: {row_idx: val, ...}, ...}                           # pandas orient='columns'
      - {row_idx: {col: val, ...}, ...}                           # pandas orient='index'
      - [[...], [...]]                                            # ì—´ ì´ë¦„ ë¯¸ìƒ (col_0.. ìƒì„±)
    """
    # ë¬¸ìì—´ì´ë©´ JSON ë¨¼ì € íŒŒì‹±
    if isinstance(table, str):
        try:
            table = json.loads(table)
        except Exception:
            return {"rows": [], "columns": [], "row_count": 0}

    # 0) ì´ë¯¸ í‘œì¤€
    if isinstance(table, dict) and "rows" in table:
        rows = table.get("rows") or []
        cols = table.get("columns") or (list(rows[0].keys()) if rows and isinstance(rows[0], dict) else [])
        return {"rows": rows, "columns": cols, "row_count": len(rows)}

    # 1) split
    if isinstance(table, dict) and "columns" in table and "data" in table and isinstance(table["data"], list):
        cols = table["columns"]
        data = table["data"]
        rows = [{cols[i]: (row[i] if i < len(row) else None) for i in range(len(cols))} for row in data]
        return {"rows": rows, "columns": cols, "row_count": len(rows)}

    # 2) table
    if isinstance(table, dict) and "schema" in table and "data" in table and isinstance(table["data"], list):
        data = table["data"]
        if data and isinstance(data[0], dict):
            cols = list(data[0].keys())
            return {"rows": data, "columns": cols, "row_count": len(data)}

    # 3) records
    if isinstance(table, list) and (not table or isinstance(table[0], dict)):
        cols = list(table[0].keys()) if table else []
        return {"rows": table, "columns": cols, "row_count": len(table)}

    # 4) columns (dict-of-dicts or dict-of-lists)
    if isinstance(table, dict) and table and all(isinstance(v, (dict, list)) for v in table.values()):
        cols = list(table.keys())
        # dict-of-dicts: {col: {row_idx: val}}
        if all(isinstance(v, dict) for v in table.values()):
            row_keys = set()
            for d in table.values():
                row_keys |= set(d.keys())

            def _ord(k):
                try: return int(k)
                except Exception:
                    try: return float(k)
                    except Exception:
                        return str(k)

            ordered = sorted(list(row_keys), key=_ord)
            rows = []
            for rk in ordered:
                row = {c: table[c].get(rk) for c in cols}
                rows.append(row)
            return {"rows": rows, "columns": cols, "row_count": len(rows)}

        # dict-of-lists: {col: [v0, v1, ...]}
        if all(isinstance(v, list) for v in table.values()):
            maxlen = max((len(v) for v in table.values()), default=0)
            rows = [{c: (table[c][i] if i < len(table[c]) else None) for c in cols} for i in range(maxlen)]
            return {"rows": rows, "columns": cols, "row_count": len(rows)}

    # 5) index orientation: {row_idx: {col: val}}
    if isinstance(table, dict) and table and all(isinstance(v, dict) for v in table.values()):
        try:
            items = list(table.items())

            def _ord2(k):
                try: return int(k)
                except Exception:
                    try: return float(k)
                    except Exception:
                        return str(k)

            items.sort(key=lambda kv: _ord2(kv[0]))
            rows = [kv[1] for kv in items]
            cols = list(rows[0].keys()) if rows else []
            return {"rows": rows, "columns": cols, "row_count": len(rows)}
        except Exception:
            pass

    # 6) list-of-lists
    if isinstance(table, list) and table and isinstance(table[0], (list, tuple)):
        max_cols = max((len(r) for r in table), default=0)
        cols = [f"col_{i}" for i in range(max_cols)]
        rows = [{cols[i]: v for i, v in enumerate(r)} for r in table]
        return {"rows": rows, "columns": cols, "row_count": len(rows)}

    return {"rows": [], "columns": [], "row_count": 0}

def _pick_col(columns: List[str], candidates: List[str]) -> Optional[str]:
    lc = [c.lower() for c in columns]
    for cand in candidates:
        if cand.lower() in lc:
            return columns[lc.index(cand.lower())]
    # ë¶€ë¶„ ì¼ì¹˜ë„ í—ˆìš©(ì˜ˆ: 'product_name', 'product')
    for i, c in enumerate(lc):
        for cand in candidates:
            if cand.lower() in c:
                return columns[i]
    return None

def _format_number(n: Any) -> str:
    try:
        x = float(n)
        # ì •ìˆ˜ì²˜ëŸ¼ ë³´ì´ë©´ ì •ìˆ˜ë¡œ, ì•„ë‹ˆë©´ ì†Œìˆ˜ 2ìë¦¬
        if abs(x - int(x)) < 1e-9:
            return f"{int(x):,}"
        return f"{x:,.2f}"
    except Exception:
        return str(n)

_NUMBER_STRIP_RE = re.compile(r"[,\sâ‚©$â‚¬Â£]|(?<=\d)\%")

def _to_float_safe(v: Any) -> Optional[float]:
    """ë¬¸ìÂ·í†µí™”Â·í¼ì„¼íŠ¸ ë“±ì„ ì•ˆì „í•˜ê²Œ float ë³€í™˜"""
    if v is None:
        return None
    if isinstance(v, (int, float)):
        return float(v)
    s = str(v).strip()
    if not s:
        return None
    # ê´„í˜¸ ìŒìˆ˜ (ì˜ˆ: (1,234))
    neg = False
    if s.startswith("(") and s.endswith(")"):
        neg = True
        s = s[1:-1]
    s = _NUMBER_STRIP_RE.sub("", s)
    try:
        x = float(s)
        return -x if neg else x
    except Exception:
        return None

def _markdown_table(rows: List[Dict[str, Any]], columns: List[str], limit: int = 10) -> str:
    if not rows:
        return "_í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤._"
    cols = columns or list(rows[0].keys())
    header = "| " + " | ".join(cols) + " |"
    sep = "| " + " | ".join(["---"] * len(cols)) + " |"
    lines = [header, sep]
    for r in rows[:limit]:
        line = "| " + " | ".join(str(r.get(c, "")) for c in cols) + " |"
        lines.append(line)
    if len(rows) > limit:
        lines.append(f"\n_í‘œì‹œëŠ” ìƒìœ„ {limit}í–‰ ë¯¸ë¦¬ë³´ê¸°ì…ë‹ˆë‹¤ (ì´ {len(rows)}í–‰)._")
    return "\n".join(lines)

def _format_period_by_datecol(rows: List[Dict[str, Any]], date_col: Optional[str]) -> str:
    """date ì—´ì´ ìˆìœ¼ë©´ min~max ê¸°ê°„ì„ í‘œì‹œ"""
    if not rows or not date_col:
        return ""
    vals = []
    for r in rows:
        v = r.get(date_col)
        if v is None:
            continue
        s = str(v)
        # ë‹¨ìˆœ íŒŒì‹± (YYYY-MM-DD, YYYY/MM/DD, YYYYMMDD ë“±)
        for fmt in ("%Y-%m-%d", "%Y/%m/%d", "%Y%m%d", "%Y-%m", "%Y/%m"):
            try:
                d = datetime.strptime(s[:len(fmt)], fmt)
                vals.append(d)
                break
            except Exception:
                continue
    if not vals:
        return ""
    start = min(vals).strftime("%Y-%m-%d")
    end = max(vals).strftime("%Y-%m-%d")
    return f" (ê¸°ê°„: {start} ~ {end})"


# =========================
# Action-State Adapter (4Â·5Â·6)
# =========================

class ActionDecision(TypedDict):
    intent_type: Literal["promotion", "none"]
    status: Literal["start_promotion", "ask_for_slots", "skip"]
    missing_slots: List[str]
    ask_prompts: List[str]
    payload: Dict[str, Any]

def _external_action_state_adapter(history: List[Dict[str, str]],
                                   active_task: Optional[ActiveTask],
                                   user_message: str) -> ActionDecision:
    """
    ì™¸ë¶€ action_state ëª¨ë“ˆ ì—°ë™ ì‹œë„.
    ì—†ë‹¤ë©´ ë‚´ë¶€ ê·œì¹™(ê³ ì • ê³„ì•½)ìœ¼ë¡œ ëŒ€ì²´.
    - íœ´ë¦¬ìŠ¤í‹± íšŒí”¼: 'í•„ìˆ˜ ìŠ¬ë¡¯'ì„ ëª…ì‹œì  ê³„ì•½ìœ¼ë¡œ ê°•ì œ
    """
    # 1) ì™¸ë¶€ ëª¨ë“ˆì´ ìˆìœ¼ë©´ ì‚¬ìš©
    try:
        # ê¸°ëŒ€ ì¸í„°í˜ì´ìŠ¤: get_action_state(history, active_task, user_message) -> ActionDecision ìœ ì‚¬ dict
        from app.agents.actions.action_state import get_action_state  # ì‚¬ìš©ìê°€ ë³„ë„ êµ¬í˜„ ì˜ˆì •
        dec = get_action_state(history=history, active_task=active_task, user_message=user_message)
        # ìµœì†Œ í•„ë“œ ë³´ì •
        return {
            "intent_type": dec.get("intent_type", "none"),
            "status": dec.get("status", "skip"),
            "missing_slots": dec.get("missing_slots", []),
            "ask_prompts": dec.get("ask_prompts", []),
            "payload": dec.get("payload", {}),
        }
    except Exception as e:
        logger.info("ì™¸ë¶€ action_state ëª¨ë“ˆ ë¯¸íƒ‘ì¬ ë˜ëŠ” ì‹¤íŒ¨: %s (ë‚´ë¶€ ê·œì¹™ ì‚¬ìš©)", e)

    # 2) ë‚´ë¶€ ê³ ì • ê³„ì•½(ë¹„íœ´ë¦¬ìŠ¤í‹±) - ActiveTask ê¸°ë°˜
    #    - active_taskê°€ ì—†ìœ¼ë©´ í”„ë¡œëª¨ì…˜ í”Œë¡œìš°ëŠ” 'skip'
    if not active_task or active_task.slots is None:
        return {
            "intent_type": "none",
            "status": "skip",
            "missing_slots": [],
            "ask_prompts": [],
            "payload": {}
        }

    slots: PromotionSlots = active_task.slots

    # í•„ìˆ˜ ìŠ¬ë¡¯(ëª…ì‹œ ê³„ì•½)
    # target_typeë³„ë¡œ í•„ìˆ˜ ìŠ¬ë¡¯ì„ ì •í™•íˆ ì •ì˜ (íœ´ë¦¬ìŠ¤í‹± ì•„ë‹˜: ê³ ì • ê·œì¹™)
    REQUIRED_COMMON = ["objective", "duration", "target_type"]
    REQUIRED_BY_TYPE = {
        "brand_target": ["brand"],
        "category_target": ["target"],
    }

    missing: List[str] = []
    # ê³µí†µ í•„ìˆ˜
    for k in REQUIRED_COMMON:
        if getattr(slots, k) in (None, "", []):
            missing.append(k)
    # íƒ€ì…ë³„
    ttype = getattr(slots, "target_type", None)
    if ttype in REQUIRED_BY_TYPE:
        for k in REQUIRED_BY_TYPE[ttype]:
            if getattr(slots, k) in (None, "", []):
                missing.append(k)
    else:
        # target_type ìì²´ê°€ ì—†ê±°ë‚˜ ë¯¸ì§€ì› ê°’ì´ë©´ ì§ˆë¬¸ í•„ìš”
        if "target_type" not in missing:
            missing.append("target_type")

    if missing:
        # ì§ˆë¬¸ ë¬¸êµ¬ëŠ” ìŠ¬ë¡¯ëª… ê·¸ëŒ€ë¡œ(í‘œì¤€í™”). ì‹¤ì œ UX ë¬¸êµ¬ëŠ” ë³„ë„ ë ˆì´ì–´ì—ì„œ ë°”ê¿€ ìˆ˜ ìˆìŒ.
        ask_prompts = []
        name_map = {
            "objective": "ì´ë²ˆ í”„ë¡œëª¨ì…˜ì˜ ëª©í‘œ(ì˜ˆ: ë§¤ì¶œ ì¦ëŒ€, ì‹ ê·œ ê³ ê° ìœ ì…)ë¥¼ ì•Œë ¤ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?",
            "duration": "í”„ë¡œëª¨ì…˜ ê¸°ê°„ì„ ì•Œë ¤ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”? (ì˜ˆ: 2025-09-01 ~ 2025-09-14)",
            "target_type": "íƒ€ê²Ÿ ì¢…ë¥˜ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”. (brand_target | category_target)",
            "brand": "íƒ€ê²Ÿ ë¸Œëœë“œë¥¼ ì•Œë ¤ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?",
            "target": "íƒ€ê²Ÿ ì¹´í…Œê³ ë¦¬/ê³ ê°êµ°ì„ ì•Œë ¤ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?",
        }
        for k in missing[:2]:  # í•œ ë²ˆì— 1~2ê°œë§Œ ë¬»ê¸°
            ask_prompts.append(name_map.get(k, f"{k} ê°’ì„ ì•Œë ¤ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?"))
        return {
            "intent_type": "promotion",
            "status": "ask_for_slots",
            "missing_slots": missing,
            "ask_prompts": ask_prompts,
            "payload": {}
        }

    # ëª¨ë“  í•„ìˆ˜ ìŠ¬ë¡¯ ì¶©ì¡± â†’ ì‹œì‘ ê°€ëŠ¥
    return {
        "intent_type": "promotion",
        "status": "start_promotion",
        "missing_slots": [],
        "ask_prompts": [],
        "payload": {
            "objective": slots.objective,
            "target_type": slots.target_type,
            "target": slots.target,
            "brand": slots.brand,
            "selected_product": slots.selected_product,
            "duration": slots.duration,
            "product_options": slots.product_options,
        },
    }

def _start_promotion(payload: Dict[str, Any]) -> str:
    """
    ì‹¤ì œ ìƒì„±ì€ ì™¸ë¶€ ì‹œìŠ¤í…œê³¼ ì—°ë™ë  ìˆ˜ ìˆìŒ.
    ì—¬ê¸°ì„œëŠ” ì‹œì‘ ì‹ í˜¸ë§Œ ë°˜í™˜(ë¶€ì‘ìš© ì—†ìŒ).
    """
    logger.info("í”„ë¡œëª¨ì…˜ ìƒì„± ì‹œì‘ (payload): %s", payload)
    # TODO: ì™¸ë¶€ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°/ë°±ì˜¤í”¼ìŠ¤ ì—°ë™ ì§€ì 
    return "í”„ë¡œëª¨ì…˜ ìƒì„±ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ì„¤ì • ìš”ì•½: " + json.dumps(payload, ensure_ascii=False)


# =========================
# Nodes
# =========================

def planner_node(state: OrchestratorState):
    logger.info("--- 1. ğŸ¤” ê³„íš ìˆ˜ë¦½ ë…¸ë“œ (Planner) ì‹¤í–‰ ---")

    parser = PydanticOutputParser(pydantic_object=OrchestratorInstruction)

    history_summary = _summarize_history(state.get("history", []))
    active_task_dump = state['active_task'].model_dump_json() if state.get('active_task') else 'null'
    schema_sig = state.get("schema_info", "") 
    today = _today_kr()

    prompt_template = textwrap.dedent("""
    You are the orchestrator for a marketing agent. Decide what to do this turn using ONLY the provided context.
    You MUST output a JSON that strictly follows: {format_instructions}

    ## Your tools (decide whether to call them this turn)
    - t2s (text-to-SQL): Use when the user's question requires factual data, aggregations, rankings, or trends derived from the company's DB. It returns a TABLE as JSON (rows/columns).
    - knowledge: Use when the user asks for external trend/insight summaries. Do NOT invent DB facts.

    ## Time normalization
    - Convert relative dates to ABSOLUTE ranges with Asia/Seoul timezone. Today is {today}.
      e.g., "ì˜¬í•´" => "{year}-01-01 ~ {today}", "ì§€ë‚œ ë‹¬" => first/last day of previous month, etc.
      If ambiguous, choose a reasonable default that does not block execution.

    ## DB schema signature (use as a hint; do not hallucinate columns beyond this):
    {schema_sig}

    ## Conversation summary (last turns):
    {history_summary}

    ## Active task (promotion) snapshot (JSON or null):
    {active_task}

    ## Decision rules (no heuristics, rely on the user's intent and schema above)
    - If the user is asking a question that requires DB facts/aggregations/ranking (e.g., "ì˜¬í•´ ì œì¼ ë§ì´ íŒ”ë¦° ìƒí’ˆì´ ë­ì˜€ì–´?"), you MUST set a clear `t2s_instruction` with explicit metrics, dimensions, sorting, and limit. Prefer revenue/quantity if applicable.
    - If the user is progressing/starting a promotion and required slots are incomplete, do NOT call tools; set `response_generator_instruction` to politely ask 1-2 questions to fill missing slots (target_type, brand/target, duration, objective).
    - If the user requests trend knowledge (not DB facts), use `knowledge_instruction`.
    - If the request is out-of-scope, set both tool instructions to null and provide a helpful guidance in `response_generator_instruction`.
    - Output should be concise and in Korean polite style.

    ## Few-shot
    Q: "ì˜¬í•´ ì œì¼ ë§ì´ íŒ”ë¦° ìƒí’ˆì´ ë­ì˜€ì–´?"
    A: t2s_instruction should describe: "{year}-01-01 ~ {today}" period, aggregate revenue and quantity by product_name, sort by revenue DESC, limit top 3.

    Q: "ë¸Œëœë“œ Aë¡œ 2ì£¼ í”„ë¡œëª¨ì…˜ ë§Œë“¤ì–´ì¤˜"
    A: Ask for any missing required slots (target_type, duration, etc.) in Korean polite style.

    Q: "ìš”ì¦˜ ìˆí¼ íŠ¸ë Œë“œ ë­ì•¼?"
    A: Use knowledge_instruction to fetch recent short-form/UGC trend highlights.

    User Message: "{user_message}"
    """)

    year = today[:4]
    prompt = ChatPromptTemplate.from_template(
        template=prompt_template,
        partial_variables={
            "format_instructions": parser.get_format_instructions()
        }
    )

    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0,
        model_kwargs={"response_format": {"type": "json_object"}},
        api_key=settings.GOOGLE_API_KEY
    )

    instructions = (prompt | llm | parser).invoke({
        "user_message": state['user_message'],
        "history_summary": history_summary,
        "active_task": active_task_dump,
        "schema_sig": schema_sig,
        "today": today,
        "year": year
    })

    return {"instructions": instructions}

def action_state_node(state: OrchestratorState):
    """
    --- 2. ğŸ“‹ ì•¡ì…˜ ìƒíƒœ í™•ì¸ ë…¸ë“œ (Action-State) ---
    4) í”„ë¡œëª¨ì…˜ ê´€ë ¨ ì—¬ë¶€ íŒë‹¨
    5) í•„ìˆ˜ ìŠ¬ë¡¯ ì¶©ì¡± ì‹œ 'start_promotion'
    6) ë¶ˆì¶©ë¶„ ì‹œ 'ask_for_slots' ì§ˆë¬¸ ìƒì„±

    - state ìŠ¤í‚¤ë§ˆ ë³€ê²½ ì—†ìŒ
    - ì™¸ë¶€ ëª¨ë“ˆ ì¡´ì¬ ì‹œ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ê³ ì • ê³„ì•½ìœ¼ë¡œ ë™ì‘
    """
    logger.info("--- 2. ğŸ“‹ ì•¡ì…˜ ìƒíƒœ í™•ì¸ ë…¸ë“œ (Action-State) ì‹¤í–‰ ---")
    decision = _external_action_state_adapter(
        history=state.get("history", []),
        active_task=state.get("active_task"),
        user_message=state.get("user_message", "")
    )
    logger.info("Action decision: %s", decision)
    # tool_resultsì— ëˆ„ì  ë³‘í•©ë  ìˆ˜ ìˆë„ë¡ ë°˜í™˜
    return {"tool_results": {"action": decision}}

def tool_executor_node(state: OrchestratorState):
    logger.info("--- 3. ğŸ”¨ íˆ´ ì‹¤í–‰ ë…¸ë“œ (Tool Executor) ì‹¤í–‰ ---")

    instructions = state.get("instructions")
    # ê¸°ì¡´ ê²°ê³¼ì™€ ë³‘í•©(ì•¡ì…˜ ë…¸ë“œ ê²°ê³¼ ìœ ì§€)
    existing_results = dict(state.get("tool_results") or {})
    if not instructions or (not instructions.t2s_instruction and not instructions.knowledge_instruction):
        logger.info("í˜¸ì¶œí•  íˆ´ì´ ì—†ìŠµë‹ˆë‹¤.")
        return {"tool_results": existing_results or None}

    tool_results: Dict[str, Any] = {}

    with ThreadPoolExecutor() as executor:
        futures = {}
        if instructions.t2s_instruction:
            futures[executor.submit(run_t2s_agent, state)] = "t2s"
        if instructions.knowledge_instruction:
            futures[executor.submit(run_knowledge_agent, instructions.knowledge_instruction)] = "knowledge"

        for future in futures:
            tool_name = futures[future]
            try:
                tool_results[tool_name] = future.result()
            except Exception as e:
                logger.error("%s íˆ´ ì‹¤í–‰ ì¤‘ ì—ëŸ¬ ë°œìƒ: %s", tool_name, e)
                tool_results[tool_name] = {"error": str(e)}

    # ì•¡ì…˜ ê²°ê³¼ì™€ ë³‘í•©
    merged = {**existing_results, **tool_results} if existing_results else tool_results
    return {"tool_results": merged}

def response_generator_node(state: OrchestratorState):
    logger.info("--- 4. ğŸ—£ï¸ ì‘ë‹µ ìƒì„± ë…¸ë“œ (Response Generator) ì‹¤í–‰ ---")

    instructions = state.get("instructions")
    tool_results = state.get("tool_results") or {}

    # LLMì— ì „ë‹¬í•  ì…ë ¥ì„ 'ê·¸ëŒ€ë¡œ' êµ¬ì„± (LLMì´ ì„œì‹/ë¶„ê¸° ëª¨ë‘ ê²°ì •)
    instructions_text = (
        instructions.response_generator_instruction
        if instructions and instructions.response_generator_instruction
        else "ì‚¬ìš©ì ìš”ì²­ì— ë§ì¶° ì •ì¤‘í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”."
    )

    # í‘œëŠ” ì •ê·œí™”ë§Œ í•´ì„œ ì „ë‹¬ (í–‰ ì¡°ë¦½/ì •ë ¬/ìˆ«ì íŒŒì‹± ë“± ì¼ì²´ ê¸ˆì§€)
    t2s_payload = tool_results.get("t2s")
    t2s_table = _normalize_table(t2s_payload) if t2s_payload else None

    action_decision = tool_results.get("action")  # action_state_node ê²°ê³¼ ê·¸ëŒ€ë¡œ
    knowledge_snippet = tool_results.get("knowledge") if isinstance(tool_results.get("knowledge"), str) else None

    # LLM í”„ë¡¬í”„íŠ¸ (ìµœì¢… ì‘ë‹µì„ LLMì´ ì§ì ‘ ì‘ì„±)
    prompt_tmpl = textwrap.dedent("""
    ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì˜ ìµœì¢… ì‘ë‹µ ìƒì„±ê¸°ì…ë‹ˆë‹¤.
    ì•„ë˜ ì…ë ¥ë§Œì„ ê·¼ê±°ë¡œ **í•œêµ­ì–´ ì¡´ëŒ“ë§**ë¡œ í•œ ë²ˆì— ì™„ì„±ëœ ë‹µë³€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.
    ë‚´ë¶€ ë„êµ¬ëª…ì´ë‚˜ ì‹œìŠ¤í…œ ì„¸ë¶€ êµ¬í˜„ì€ ì–¸ê¸‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

    [ì…ë ¥ ì„¤ëª…]
    - instructions_text: ì´ë²ˆ í„´ì—ì„œ ì–´ë–¤ í†¤/ë°©í–¥ìœ¼ë¡œ ì‘ë‹µí•´ì•¼ í•˜ëŠ”ì§€ì— ëŒ€í•œ ìƒìœ„ ì§€ì‹œ.
    - action_decision: í”„ë¡œëª¨ì…˜ ê´€ë ¨ ì˜ì‚¬ê²°ì • ê²°ê³¼ ì˜¤ë¸Œì íŠ¸(ì¡´ì¬í•  ìˆ˜ë„, ì—†ì„ ìˆ˜ë„ ìˆìŒ).
        ì˜ˆ) {{
          "intent_type": "promotion" | "none",
          "status": "start_promotion" | "ask_for_slots" | "skip",
          "missing_slots": [...],
          "ask_prompts": [...],
          "payload": {{...}}
        }}
    - t2s_table: íšŒì‚¬ DBë¡œë¶€í„° ìƒì„±ëœ ì§ˆì˜ ê²°ê³¼ í‘œ. í˜•ì‹ì€ {{
        "rows": [{{...}}, ...],
        "columns": ["colA", "colB", ...],
        "row_count": N
      }} ë˜ëŠ” None.
      â€» í‘œê°€ ìˆë‹¤ë©´ í‘œ **ë‚´ìš©ë§Œ** ì‚¬ìš©í•˜ì—¬ ì‚¬ì‹¤ì„ ë§í•´ ì£¼ì„¸ìš”. ìƒˆë¡œìš´ ìˆ˜ì¹˜/ì‚¬ì‹¤ ì°½ì‘ ê¸ˆì§€.
      â€» í‘œê°€ ë§¤ìš° í¬ë”ë¼ë„ **ë¯¸ë¦¬ë³´ê¸° ìš©ë„ë¡œ ìƒìœ„ 10í–‰ë§Œ** ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ë³´ì—¬ ì£¼ì„¸ìš”(ì—´ ìˆœì„œëŠ” columns ê¸°ì¤€).
    - knowledge_snippet: ì™¸ë¶€ íŠ¸ë Œë“œ ìš”ì•½ ë¬¸ìì—´(ìˆì„ ìˆ˜ë„, ì—†ì„ ìˆ˜ë„ ìˆìŒ).

    [ì‘ì„± ì§€ì¹¨]
    1) instructions_textë¥¼ ìµœìƒìœ„ ê°€ì´ë“œë¡œ ì‚¼ì•„ í†¤ê³¼ ë²”ìœ„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
    2) action_decisionì´ ì¡´ì¬í•˜ë©´:
       - status=="ask_for_slots"ì¸ ê²½ìš°, ask_promptsì— ë“¤ì–´ìˆëŠ” ì§ˆë¬¸ì„ **ì •ì¤‘í•˜ê²Œ 1~2ë¬¸ì¥ìœ¼ë¡œ** ìì—°ìŠ¤ëŸ½ê²Œ ë¬¼ì–´ë³´ì„¸ìš”.
       - status=="start_promotion"ì¸ ê²½ìš°, payloadì˜ í•µì‹¬ ì„¤ì •ì„ **ì§§ê²Œ ìš”ì•½**í•˜ê³  ì‹œì‘ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.
       - "skip"ì´ê±°ë‚˜ ì—†ìœ¼ë©´ ë¬´ì‹œí•©ë‹ˆë‹¤.
    3) t2s_tableì´ ì¡´ì¬í•˜ë©´:
       - í‘œë¥¼ ê·¼ê±°ë¡œ í•µì‹¬ í¬ì¸íŠ¸ë¥¼ **ê°„ê²°íˆ ìš”ì•½**í•˜ì„¸ìš”(ì˜ˆ: ëˆˆì— ë„ëŠ” í•­ëª©/ì¦ê°/ë¹„ì¤‘ ë“±).
       - í‘œ **ë¯¸ë¦¬ë³´ê¸°(ìµœëŒ€ 10í–‰)**ë¥¼ ë§ˆí¬ë‹¤ìš´ í‘œë¡œ í¬í•¨í•˜ì„¸ìš”.
       - ì—´ ì´ë¦„ì´ í‘œì¤€í™”ë˜ì–´ ìˆì§€ ì•Šì•„ë„ ì¶”ì¸¡í•˜ì§€ ë§ê³  **ìˆëŠ” ê°’ë§Œ** ì‚¬ìš©í•˜ì„¸ìš”.
    4) knowledge_snippetì´ ìˆìœ¼ë©´ "ì°¸ê³  íŠ¸ë Œë“œ"ë¡œ 1~2ì¤„ë§Œ ë§ë¶™ì—¬ ì£¼ì„¸ìš”.
    5) ë°ì´í„°ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ê²°ë¡ ì´ ì–´ë ¤ìš°ë©´, ì •ì¤‘í•˜ê²Œ í•œ ë¬¸ì¥ìœ¼ë¡œ í•œê³„ë¥¼ ë°íˆê³  ë‹¤ìŒ ì•¡ì…˜ì„ ì œì•ˆí•˜ì„¸ìš”.
    6) ì „ë°˜ì ìœ¼ë¡œ **ê°„ê²°í•˜ê³  êµ¬ì¡°í™”**(ë¶ˆë¦¿/ì§§ì€ ë‹¨ë½)í•˜ë©°, í•œêµ­ì–´ ì¡´ëŒ“ë§ì„ ìœ ì§€í•˜ì„¸ìš”.

    [ì…ë ¥ ë°ì´í„°]
    - instructions_text:
    {instructions_text}

    - action_decision (JSON):
    {action_decision_json}

    - t2s_table (JSON):
    {t2s_table_json}

    - knowledge_snippet:
    {knowledge_snippet}
    """)

    # JSON ì§ë ¬í™”(LLMì´ ê·¸ëŒ€ë¡œ ì½ë„ë¡): ê°€ê³µÂ·í•´ì„ ì—†ì´ ì „ë‹¬
    action_json = json.dumps(action_decision, ensure_ascii=False) if action_decision is not None else "null"
    table_json = json.dumps(t2s_table, ensure_ascii=False) if t2s_table is not None else "null"

    prompt = ChatPromptTemplate.from_template(prompt_tmpl)
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0,
        api_key=settings.GOOGLE_API_KEY
    )

    final_text = (prompt | llm).invoke({
        "instructions_text": instructions_text,
        "action_decision_json": action_json,
        "t2s_table_json": table_json,
        "knowledge_snippet": knowledge_snippet or ""
    })

    # ëª¨ë¸ ê°ì²´/ë¬¸ìì—´ í˜¸í™˜
    final_response = getattr(final_text, "content", None) or str(final_text)

    logger.info(f"ìµœì¢… ê²°ê³¼(L):\n{final_response}")

    history = state.get("history", [])
    history.append({"role": "user", "content": state.get("user_message", "")})
    history.append({"role": "assistant", "content": final_response})

    return {"history": history, "user_message": "", "output": final_response}


# =========================
# Graph
# =========================
workflow = StateGraph(OrchestratorState)

workflow.add_node("planner", planner_node)
workflow.add_node("action_state", action_state_node)       
workflow.add_node("tool_executor", tool_executor_node)
workflow.add_node("response_generator", response_generator_node)

workflow.set_entry_point("planner")
workflow.add_edge("planner", "action_state")               
workflow.add_edge("action_state", "tool_executor")         
workflow.add_edge("tool_executor", "response_generator")
workflow.add_edge("response_generator", END)

orchestrator_app = workflow.compile()
