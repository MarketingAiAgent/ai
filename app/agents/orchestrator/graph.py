from __future__ import annotations

import json
import textwrap
import logging
from typing import List, Optional, Dict, Any, Literal, TypedDict, Union
from concurrent.futures import ThreadPoolExecutor
from datetime import timedelta

from pydantic import BaseModel, Field
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers.pydantic import PydanticOutputParser
from langgraph.graph import StateGraph, END

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_anthropic import ChatAnthropic

from app.core.config import settings
from app.database.promotion_slots import update_state
from app.agents.promotion.state import get_action_state
from app.agents.visualizer.graph import build_visualize_graph
from app.agents.visualizer.state import VisualizeState
from .state import *
from .tools import *
from .helpers import *

logger = logging.getLogger(__name__)

# ===== Nodes =====
def _merge_slots(state: OrchestratorState, updates: Dict[str, Any]) -> PromotionSlots:
    current = (state.get("active_task").slots if state.get("active_task") and state.get("active_task").slots else PromotionSlots())
    base = current.model_dump()
    for k, v in updates.items():
        if v not in (None, "", []):
            base[k] = v
    merged = PromotionSlots(**base)
    if state.get("active_task"):
        state["active_task"].slots = merged
    return merged

def slot_extractor_node(state: OrchestratorState):
    logger.info("--- ğŸ” ìŠ¬ë¡¯ ì¶”ì¶œ/ì €ì¥ ë…¸ë“œ ì‹¤í–‰ ---")
    user_message = state.get("user_message", "")
    chat_id = state["chat_id"]

    parser = PydanticOutputParser(pydantic_object=PromotionSlotUpdate)
    prompt_tmpl = textwrap.dedent("""
    ì•„ë˜ í•œêµ­ì–´ ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ **í”„ë¡œëª¨ì…˜ ìŠ¬ë¡¯ ê°’**ì„ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.
    - ì¡´ì¬í•˜ëŠ” ê°’ë§Œ ì±„ìš°ê³ , ì—†ìœ¼ë©´ nullë¡œ ë‘ì„¸ìš”.
    - target_typeì€ "brand_target" ë˜ëŠ” "category_target" ì¤‘ í•˜ë‚˜ë¡œë§Œ.
    - ë‚ ì§œ/ê¸°ê°„ì€ ì›ë¬¸ ê·¸ëŒ€ë¡œ ë¬¸ìì—´ë¡œ ìœ ì§€.
    - ì¶œë ¥ì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¥´ì„¸ìš”:
      {format_instructions}

    [ì‚¬ìš©ì ë©”ì‹œì§€]
    {user_message}
    """)
    prompt = ChatPromptTemplate.from_template(
        prompt_tmpl,
        partial_variables={"format_instructions": parser.get_format_instructions()}
    )
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0,
        model_kwargs={"response_format": {"type": "json_object"}},
        api_key=settings.GOOGLE_API_KEY
    )
    parsed: PromotionSlotUpdate = (prompt | llm | parser).invoke({"user_message": user_message})

    updates = {k: v for k, v in parsed.model_dump().items() if v not in (None, "", [])}
    if not updates:
        logger.info("ìŠ¬ë¡¯ ì—…ë°ì´íŠ¸ ì—†ìŒ")
        return {}

    try:
        update_state(chat_id, updates)
        logger.info("Mongo ìƒíƒœ ì—…ë°ì´íŠ¸: %s", updates)
    except Exception as e:
        logger.error("Mongo ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: %s", e)

    merged = _merge_slots(state, updates)
    logger.info("State ìŠ¬ë¡¯ ë³‘í•©: %s", merged.model_dump())
    return {"tool_results": {"slot_updates": updates}}

def _planner_router(state: OrchestratorState) -> str:
    instr = state.get("instructions")
    if not instr:
        return "tool_executor"
        
    resp = (instr.response_generator_instruction or "").strip()
    if resp.startswith("[PROMOTION]"):
        return "slot_extractor"
        
    if instr.tool_calls and len(instr.tool_calls) > 0:
        return "tool_executor"
        
    return "response_generator"

def planner_node(state: OrchestratorState):
    logger.info("--- ğŸ¤” ê³„íš ìˆ˜ë¦½ ë…¸ë“œ ì‹¤í–‰ ---")

    parser = PydanticOutputParser(pydantic_object=OrchestratorInstruction)
    history_summary = summarize_history(state.get("history", []))
    active_task_dump = state['active_task'].model_dump_json() if state.get('active_task') else 'null'
    schema_sig = state.get("schema_info", "")
    today = today_kr()

    prompt_template = textwrap.dedent("""
    You are the orchestrator for a marketing agent. Decide what to do this turn using ONLY the provided context.
    You MUST output a JSON that strictly follows: {format_instructions}

    ## Route decision (VERY IMPORTANT)
    - Decide the user's intent as one of:
      - Promotion flow (create/continue a promotion)
      - One-off answer (DB facts via t2s, or knowledge snippet)
      - Out-of-scope guidance
    - If and only if it is **promotion flow**, prefix `response_generator_instruction` with "[PROMOTION]".
    - If it is **out-of-scope guidance**, prefix with "[OUT_OF_SCOPE]".
    - Otherwise (one-off answer), no prefix.

    ## Tools
    - ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ í•„ìš”í•œ ëª¨ë“  ë„êµ¬ë¥¼ **tool_calls JSON ë°°ì—´**ì— ë‹´ì•„ ìš”ì²­í•˜ì„¸ìš”.
    - í•„ìš”í•˜ë‹¤ë©´ **ì—¬ëŸ¬ ê°œì˜ ë„êµ¬ë¥¼ í•˜ë‚˜ì˜ ë°°ì—´ì— ë™ì‹œì— ìš”ì²­**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ê° ë„êµ¬ ê°ì²´ëŠ” `{{"tool": "ë„êµ¬ëª…", "args": {{"íŒŒë¼ë¯¸í„°ëª…": "ê°’"}}}}` í˜•ì‹ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.
    - ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ê³¼ í˜•ì‹:
      - DB ì¡°íšŒ: `{{"tool": "t2s", "args": {{"instruction": "SQLë¡œ ë³€í™˜í•  ìì—°ì–´ ì§ˆë¬¸"}}}}`
      - ì›¹ ê²€ìƒ‰: `{{"tool": "tavily_search", "args": {{"query": "ê²€ìƒ‰ì–´", "max_results": 5}}}}`
      - ì›¹ ìŠ¤í¬ë˜í•‘: `{{"tool": "scrape_webpages", "args": {{"urls": ["https://...", ...]}}}}`
      - ë§ˆì¼€íŒ… íŠ¸ë Œë“œ: `{{"tool": "marketing_trend_search", "args": {{"question": "ì§ˆë¬¸"}}}}`
      - ë·°í‹° íŠ¸ë Œë“œ: `{{"tool": "beauty_youtuber_trend_search", "args": {{"question": "ì§ˆë¬¸"}}}}`
    - ë„êµ¬ ì‚¬ìš©ì´ í•„ìš” ì—†ìœ¼ë©´ `tool_calls` í•„ë“œë¥¼ nullë¡œ ë‘ì„¸ìš”.

    ## Time normalization
    - Convert relative dates to ABSOLUTE ranges with Asia/Seoul timezone. Today is {today}.

    ## DB schema signature (hint only):
    {schema_sig}

    ## Conversation summary (last turns):
    {history_summary}

    ## Active task snapshot (JSON or null):
    {active_task}

    ## Decision rules
    - Promotion flow: do NOT call tools this turn. Just set `response_generator_instruction` (with [PROMOTION]).
    - One-off answers: set `tool_calls` as needed.
    - Out-of-scope: both tools null, and provide short polite guidance with [OUT_OF_SCOPE].
    - Output must be concise, Korean polite style.

    User Message: "{user_message}"
    """)

    prompt = ChatPromptTemplate.from_template(
        template=prompt_template,
        partial_variables={"format_instructions": parser.get_format_instructions()}
    )
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0,
        model_kwargs={"response_format": {"type": "json_object"}},
        api_key=settings.GOOGLE_API_KEY
    )

    instructions = (prompt | llm | parser).invoke({
        "user_message": state['user_message'],
        "history_summary": history_summary,
        "active_task": active_task_dump,
        "schema_sig": schema_sig,
        "today": today,
    })

    return {"instructions": instructions}

def action_state_node(state: OrchestratorState):
    logger.info("--- ğŸ“‹ ì•¡ì…˜ ìƒíƒœ í™•ì¸ ë…¸ë“œ ì‹¤í–‰ ---")
    slots = state.get("active_task").slots if state.get("active_task") and state.get("active_task").slots else None
    decision = get_action_state(slots=slots)
    logger.info("Action decision: %s", decision)
    return {"tool_results": {"action": decision}}

def _action_router(state: OrchestratorState) -> str:
    """
    action_state ê²°ê³¼ë¡œ ë‹¤ìŒ ë…¸ë“œ ê²°ì •:
    - brand/targetì„ ë¬»ê±°ë‚˜, íŠ¹ì • productë¥¼ ë¬¼ì–´ì•¼ í•˜ëŠ” ìƒí™©ì´ë©´ options_generatorë¡œ ë¶„ê¸°
    - ê·¸ ì™¸ (objective/duration ì§ˆë¬¸, ìµœì¢… í™•ì¸ ë“±)ëŠ” response_generatorë¡œ ë¶„ê¸°
    """
    tr = state.get("tool_results") or {}
    action = tr.get("action") or {}
    status = action.get("status")
    missing = action.get("missing_slots", [])

    # --- ğŸ‘‡ ì—¬ê¸°ê°€ í•µì‹¬ì ì¸ ë³€ê²½ ë¶€ë¶„ì…ë‹ˆë‹¤ ---
    # 'ask_for_product' ìƒíƒœì¼ ë•Œ options_generatorë¥¼ í˜¸ì¶œí•˜ë„ë¡ ëª…ì‹œ
    if status == "ask_for_product":
        return "options_generator"
    # ------------------------------------
    
    # ê¸°ì¡´ ë¡œì§: brandë‚˜ targetì„ ë¬¼ì–´ì•¼ í•  ë•Œë„ options_generator í˜¸ì¶œ
    if status == "ask_for_slots" and any(m in ("brand", "target") for m in missing):
        return "options_generator"
        
    return "response_generator"
    
def _build_candidate_t2s_instruction(target_type: str, slots: PromotionSlots) -> str:
    end = datetime.now(ZoneInfo("Asia/Seoul")).date()
    start = end - timedelta(days=60)
    
    # --- ğŸ‘‡ ì—¬ê¸°ê°€ í•µì‹¬ì ì¸ ë³€ê²½ ë¶€ë¶„ì…ë‹ˆë‹¤ ---
    # ë¸Œëœë“œ í•„í„°ë§ ì¡°ê±´ì„ ë‹´ì„ ë³€ìˆ˜
    brand_filter_instruction = ""
    # slotsì— brand ì •ë³´ê°€ ìˆìœ¼ë©´ í•„í„°ë§ ì§€ì‹œë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    if slots and slots.brand:
        brand_filter_instruction = f" ë˜í•œ, ê²°ê³¼ëŠ” ë°˜ë“œì‹œ '{slots.brand}' ë¸Œëœë“œì˜ ì œí’ˆë§Œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤."
    # ------------------------------------
 
    if target_type == "brand_target":
        return textwrap.dedent(f"""
        ìµœê·¼ ê¸°ê°„ {start}~{end}ì™€ ì§ì „ ë™ì¼ ê¸°ê°„ì„ ë¹„êµí•˜ì—¬ ë¸Œëœë“œ ë ˆë²¨ í›„ë³´ ëª©ë¡ì„ ì‚°ì¶œí•´ ì£¼ì„¸ìš”.{brand_filter_instruction}
        ë°˜ë“œì‹œ ë‹¤ìŒ ì»¬ëŸ¼ aliasë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
        - brand_name
        - revenue (ìµœê·¼ ê¸°ê°„ ë§¤ì¶œ)
        - growth_pct (ì´ì „ ë™ì¼ê¸°ê°„ ëŒ€ë¹„ ì¦ê°ìœ¨, %)
        - gm (ìµœê·¼ ê¸°ê°„ ì´ì´ìµë¥ , 0~1)
        - conversion_rate
        - repeat_rate
        - aov
        - inventory_days
        - return_rate
        - category_name
        - price_band
        - gender_age
        í–‰ì€ ë¸Œëœë“œë³„ 1í–‰ì…ë‹ˆë‹¤. ìµœê·¼ ê¸°ê°„ ë§¤ì¶œ ìƒìœ„ 100ê°œ ë‚´ì—ì„œ ë°˜í™˜í•´ ì£¼ì„¸ìš”.
        """).strip()
    else:
        return textwrap.dedent(f"""
        ìµœê·¼ ê¸°ê°„ {start}~{end}ì™€ ì§ì „ ë™ì¼ ê¸°ê°„ì„ ë¹„êµí•˜ì—¬ ì¹´í…Œê³ ë¦¬/ìƒí’ˆ ë ˆë²¨ í›„ë³´ ëª©ë¡ì„ ì‚°ì¶œí•´ ì£¼ì„¸ìš”.
        ê°€ëŠ¥í•œ ê²½ìš° ë‹¤ìŒ ì»¬ëŸ¼ aliasë¥¼ í¬í•¨í•˜ì„¸ìš”:
        - product_id
        - product_name
        - category_name
        - revenue
        - growth_pct
        - gm
        - conversion_rate
        - repeat_rate
        - aov
        - inventory_days
        - return_rate
        - price_band
        - gender_age
        í–‰ì€ ìƒí’ˆ(ë˜ëŠ” ì¹´í…Œê³ ë¦¬)ë³„ 1í–‰ì…ë‹ˆë‹¤. ìµœê·¼ ê¸°ê°„ ë§¤ì¶œ ìƒìœ„ 200ê°œ ë‚´ì—ì„œ ë°˜í™˜í•´ ì£¼ì„¸ìš”.
        """).strip()

def options_generator_node(state: OrchestratorState):
    logger.info("--- ğŸ§  ì˜µì…˜ ì œì•ˆ ë…¸ë“œ ì‹¤í–‰ ---")
    chat_id = state["chat_id"]
    slots = state.get("active_task").slots if state.get("active_task") and state.get("active_task").slots else PromotionSlots()
    target_type = slots.target_type or "brand_target"

    t2s_instr = _build_candidate_t2s_instruction(target_type, slots)
    table = run_t2s_agent_with_instruction(state, t2s_instr)
    rows = table["rows"]

    if not rows:
        logger.warning("t2s í›„ë³´ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        update_state(chat_id, {"product_options": []})
        tr = state.get("tool_results") or {}
        tr["option_candidates"] = {"candidates": [], "method": "deterministic_v1", "time_window": "", "constraints": {}}
        return {"tool_results": tr}

    knowledge = get_knowledge_snapshot()
    trending_terms = knowledge.get("trending_terms", [])

    enriched = compute_opportunity_score(rows, trending_terms)
    topk = pick_diverse_top_k(enriched, k=4)

    labels: List[str] = []
    candidates: List[Dict[str, Any]] = []
    for r in topk:
        if target_type == "brand_target":
            cid = f"brand:{r.get('brand_name')}"
            label = str(r.get("brand_name") or "ì•Œ ìˆ˜ ì—†ëŠ” ë¸Œëœë“œ")
            typ = "brand"
        else:
            name = r.get("product_name") or r.get("category_name") or "ì•Œ ìˆ˜ ì—†ëŠ” í•­ëª©"
            cid = f"product:{r.get('product_id') or name}"
            label = str(name)
            typ = "product" if r.get("product_name") else "category"
        labels.append(label)
        candidates.append({
            "id": cid,
            "label": label,
            "type": typ,
            "metrics": {k: r.get(k) for k in (
                "revenue","growth_pct","gm","conversion_rate","repeat_rate","aov","inventory_days","seasonality_score","return_rate"
            ) if k in r},
            "opportunity_score": r.get("opportunity_score"),
            "reasons": r.get("reasons", []),
            "diversity_tags": [x for x in (r.get("category_name"), r.get("price_band"), r.get("gender_age")) if x],
        })

    option_json = {
        "candidates": candidates,
        "method": "deterministic_v1",
        "time_window": "",
        "constraints": {"min_gm": 0.25, "max_return_rate": 0.1},
    }


    try:
        update_state(chat_id, {"product_options": labels})
    except Exception as e:
        logger.error("ì˜µì…˜ ë¼ë²¨ ì €ì¥ ì‹¤íŒ¨: %s", e)


    merged_slots = _merge_slots(state, {"product_options": labels})
    logger.info("ì˜µì…˜ ë¼ë²¨ state ë°˜ì˜: %s", merged_slots.product_options)


    tr = state.get("tool_results") or {}
    tr["option_candidates"] = option_json
    return {"tool_results": tr}

def _parse_knowledge_calls(instr: Optional[Union[str, List[Dict[str, Any]], Dict[str, Any]]]) -> List[Dict[str, Any]]:
    if instr is None:
        return []

    if isinstance(instr, dict):
        return [instr]

    if isinstance(instr, list):
        # ensure list of dicts
        return [c for c in instr if isinstance(c, dict)]

    if isinstance(instr, str):
        try:
            data = json.loads(instr)
            if isinstance(data, dict):
                return [data]
            if isinstance(data, list):
                return [c for c in data if isinstance(c, dict)]
            return []
        except Exception:

            return []
    return []


def tool_executor_node(state: OrchestratorState):
    logger.info("--- ğŸ”¨ íˆ´ ì‹¤í–‰ ë…¸ë“œ ì‹¤í–‰ ---")
    instructions = state.get("instructions")
    tool_calls = instructions.tool_calls if instructions and instructions.tool_calls else []

    if not tool_calls:
        logger.info("ì‹¤í–‰í•  íˆ´ì´ ì—†ìŠµë‹ˆë‹¤.")
        return {"tool_results": None}

    tool_map = {
        "t2s": lambda args: run_t2s_agent_with_instruction(state, args.get("instruction", "")),
        "tavily_search": lambda args: run_tavily_search(args.get("query", ""), args.get("max_results", 5)),
        "scrape_webpages": lambda args: scrape_webpages(args.get("urls", [])),
        "marketing_trend_search": lambda args: marketing_trend_search(args.get("question", "")),
        "beauty_youtuber_trend_search": lambda args: beauty_youtuber_trend_search(args.get("question", "")),
    }
    
    tool_results = {}

    with ThreadPoolExecutor(max_workers=len(tool_calls)) as executor:
        future_to_call = {}
        for i, call in enumerate(tool_calls):
            tool_name = call.get("tool")
            tool_args = call.get("args", {})

            logger.info(f"ğŸ§© {tool_name} ì‹¤í–‰")
            
            if tool_name in tool_map:
                result_key = f"{tool_name}_{i}"
                future = executor.submit(tool_map[tool_name], tool_args)
                future_to_call[future] = result_key
            else:
                logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬ '{tool_name}' í˜¸ì¶œì€ ê±´ë„ˆëœë‹ˆë‹¤.")
        
        for future in future_to_call:
            result_key = future_to_call[future]

            try:
                result = future.result()
                tool_results[result_key] = result

            except Exception as e:
                logger.error(f"'{result_key}' íˆ´ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                tool_results[result_key] = {"error": str(e)}


    existing_results = state.get("tool_results") or {}
    merged_results = {**existing_results, **tool_results}
    
    return {"tool_results": merged_results}

def _should_visualize_router(state: OrchestratorState) -> str:
    tool_results = state.get("tool_results", {})
    # tool_results ì•ˆì— t2së¡œ ì‹œì‘í•˜ê³  ë°ì´í„°ê°€ ìˆëŠ” ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
    for key, value in tool_results.items():
        if key.startswith("t2s") and value and value.get("rows"):
            logger.info("T2S ê²°ê³¼ê°€ ìˆì–´ ì‹œê°í™”ë¥¼ ì‹œë„í•©ë‹ˆë‹¤.")
            return "visualize"
            
    logger.info("T2S ê²°ê³¼ê°€ ì—†ì–´ ì‹œê°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
    return "skip_visualize"

def visualizer_caller_node(state: OrchestratorState):
    logger.info("--- ğŸ“Š ì‹œê°í™” ë…¸ë“œ ì‹¤í–‰ ---")
    
    # t2s ê²°ê³¼ë¥¼ ì°¾ìŠµë‹ˆë‹¤. ì—¬ëŸ¬ tool_results ì¤‘ t2s_0, t2s_1 ë“±ì„ ì°¾ë„ë¡ ìˆ˜ì •
    t2s_result = None
    tool_results = state.get("tool_results", {})
    for key, value in tool_results.items():
        if key.startswith("t2s") and value and value.get("rows"):
            t2s_result = value
            break
    
    if not t2s_result:
        logger.info("ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
        return {}

    # Visualizer ê·¸ë˜í”„ ì‹¤í–‰
    visualizer_app = build_visualize_graph(model="gemini-2.5-flash") # ëª¨ë¸ëª…ì€ ì„¤ì •ì— ë”°ë¼ ë³€ê²½
    viz_state = VisualizeState(
        user_question=state.get("user_message"),
        instruction="ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ì•„ë˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì ì˜ ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ê³  ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        json_data=json.dumps(t2s_result, ensure_ascii=False)
    )
    
    viz_response = visualizer_app.invoke(viz_state)

    # ì‹œê°í™” ê²°ê³¼ë¥¼ tool_resultsì— ì¶”ê°€
    if viz_response:
        tool_results["visualization"] = {
            "json_graph": viz_response.get("json_graph"),
            "explanation": viz_response.get("output")
        }
        
    return {"tool_results": tool_results}

def response_generator_node(state: OrchestratorState):
    logger.info("--- ğŸ—£ï¸ ì‘ë‹µ ìƒì„± ë…¸ë“œ ---")
    instructions = state.get("instructions")
    tr = state.get("tool_results") or {}

    instructions_text = (
        instructions.response_generator_instruction
        if instructions and instructions.response_generator_instruction
        else "ì‚¬ìš©ì ìš”ì²­ì— ë§ì¶° ì •ì¤‘í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”."
    )

    t2s_table = None
    web_search = None
    scraped_pages = None
    marketing_trend_results = None
    youtuber_trend_results = None
    for key, value in tr.items():
        if key.startswith("t2s") and isinstance(value, dict) and "rows" in value:
            t2s_table = value
        elif key.startswith("web_search"): 
            web_search = value
        elif key.startswith("scraped_pages"):
            scraped_pages = value
        elif key.startswith("marketing_trend_results"):
            marketing_trend_results = value
        elif key.startswith("beauty_youtuber_trend_search"):
            youtuber_trend_results = value

    action_decision = tr.get("action")
    knowledge_snippet = tr.get("knowledge") if isinstance(tr.get("knowledge"), str) else None
    option_candidates = tr.get("option_candidates") if isinstance(tr.get("option_candidates"), dict) else None

    prompt_tmpl = textwrap.dedent("""
    ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì˜ ìµœì¢… ì‘ë‹µ ìƒì„±ê¸°ì…ë‹ˆë‹¤.
    ì•„ë˜ ì…ë ¥ë§Œì„ ê·¼ê±°ë¡œ **í•œêµ­ì–´ ì¡´ëŒ“ë§**ë¡œ í•œ ë²ˆì— ì™„ì„±ëœ ë‹µë³€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.
    ë‚´ë¶€ ë„êµ¬ëª…ì´ë‚˜ ì‹œìŠ¤í…œ ì„¸ë¶€ êµ¬í˜„ì€ ì–¸ê¸‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

    [ì…ë ¥ ì„¤ëª…]
    - instructions_text: ì´ë²ˆ í„´ì˜ í†¤/ë°©í–¥.
    - action_decision: í”„ë¡œëª¨ì…˜ ì˜ì‚¬ê²°ì •(JSON).
    - option_candidates: ìœ ì €ì—ê²Œ ì œì•ˆí•  í›„ë³´ ëª©ë¡(JSON).
    - t2s_table: DB ì§ˆì˜ ê²°ê³¼(JSON). ìˆìœ¼ë©´ ìƒìœ„ 10í–‰ë§Œ í‘œë¡œ ë¯¸ë¦¬ë³´ê¸°.
    - knowledge_snippet: ê°„ë‹¨ ì°¸ê³ (ì„ íƒ).
    - web_search: ì›¹ ê²€ìƒ‰ ê²°ê³¼(JSON: results[title,url,content]).
    - scraped_pages: ì›¹ í˜ì´ì§€ ë³¸ë¬¸ ìŠ¤í¬ë˜í•‘ ê²°ê³¼(JSON: documents[source,content]).
    - marketing_trend_results: Supabase ë§ˆì¼€íŒ… íŠ¸ë Œë“œ ê²°ê³¼(JSON).
    - youtuber_trend_results: Supabase ë·°í‹° ìœ íŠœë²„ íŠ¸ë Œë“œ ê²°ê³¼(JSON).

    [ì‘ì„± ì§€ì¹¨]
    1) **ê°€ì¥ ì¤‘ìš”í•œ ê·œì¹™**: `action_decision` ê°ì²´ê°€ ìˆê³ , ê·¸ ì•ˆì˜ `ask_prompts` ë¦¬ìŠ¤íŠ¸ì— ë‚´ìš©ì´ ìˆë‹¤ë©´, ë‹¹ì‹ ì˜ ìµœìš°ì„  ì„ë¬´ëŠ” í•´ë‹¹ ë¦¬ìŠ¤íŠ¸ì˜ ì§ˆë¬¸ì„ ì‚¬ìš©ìì—ê²Œ í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë‹¤ë¥¸ ëª¨ë“  ì§€ì‹œë³´ë‹¤ ì´ ê·œì¹™ì„ **ë°˜ë“œì‹œ** ë”°ë¼ì•¼ í•©ë‹ˆë‹¤. `ask_prompts`ì˜ ë¬¸êµ¬ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê±°ë‚˜, ì‚´ì§ ë” ìì—°ìŠ¤ëŸ½ê²Œë§Œ ë‹¤ë“¬ì–´ ì§ˆë¬¸í•˜ì„¸ìš”. (ì˜ˆ: "íƒ€ê²Ÿ ì¢…ë¥˜ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”. (brand_target | category_target)")
    2) ìœ„ 1ë²ˆ ê·œì¹™ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ë§Œ, `instructions_text`ë¥¼ ì£¼ëœ ë‚´ìš©ìœ¼ë¡œ ì‚¼ì•„ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    3) `option_candidates`ê°€ ìˆìœ¼ë©´ ë²ˆí˜¸ë¡œ ì œì‹œí•˜ê³  ê° 2~4ì¤„ ê·¼ê±°ë¥¼ ë¶™ì…ë‹ˆë‹¤. ëª¨ë“  ìˆ˜ì¹˜ëŠ” ì–´ë–¤ ìˆ˜ì¹˜ì¸ì§€ êµ¬ì²´ì ì¸ ì–¸ê¸‰ì„ í•´ì£¼ì„¸ìš”. ë§ˆì§€ë§‰ì— 'ê¸°íƒ€(ì§ì ‘ ì…ë ¥)'ë„ ì¶”ê°€í•©ë‹ˆë‹¤.    
    4) web_search / scraped_pages / supabase ê²°ê³¼ê°€ ìˆìœ¼ë©´, í•µì‹¬ ê·¼ê±°ë¥¼ 2~4ì¤„ë¡œ ìš”ì•½í•´ ì„¤ëª…ì— ë…¹ì—¬ ì£¼ì„¸ìš”. ì›ë¬¸ ì¸ìš©ì€ 1~2ë¬¸ì¥ ì´í•˜ë¡œ ì œí•œ.
    5) t2s_tableì´ ìˆìœ¼ë©´ ìƒìœ„ 10í–‰ ë¯¸ë¦¬ë³´ê¸° í‘œë¥¼ í¬í•¨í•˜ë˜, ì—†ëŠ” ìˆ˜ì¹˜ëŠ” ë§Œë“¤ì§€ ë§ˆì„¸ìš”. í‘œë¥¼ ì‹œì‘í•˜ëŠ” ë¶€ë¶„ì€ [TABLE_START] í‘œê°€ ëë‚˜ëŠ” ë¶€ë¶„ì€ [TABLE_END] ë¼ëŠ” í…ìŠ¤íŠ¸ë¥¼ ë¶™ì—¬ì„œ ì–´ë””ë¶€í„° ì–´ë””ê°€ í…Œì´ë¸”ì¸ì§€ ì•Œ ìˆ˜ ìˆê²Œ í•´ì£¼ì„¸ìš”.
    6) ì „ì²´ì ìœ¼ë¡œ êµ¬ì¡°í™”ëœ í˜•ì‹ì„ ìœ ì§€í•˜ì„¸ìš”.

    [ì…ë ¥ ë°ì´í„°]
    - instructions_text:
    {instructions_text}

    - action_decision (JSON):
    {action_decision_json}

    - option_candidates (JSON):
    {option_candidates_json}

    - t2s_table (JSON):
    {t2s_table_json}

    - web_search (JSON):
    {web_search_json}

    - scraped_pages (JSON):
    {scraped_pages_json}

    - marketing_trend_results (JSON):
    {marketing_trend_results_json}

    - youtuber_trend_results (JSON):
    {youtuber_trend_results_json}

    - knowledge_snippet:
    {knowledge_snippet}
    """)

    to_json = lambda x: json.dumps(x, ensure_ascii=False) if x is not None else "null"

    prompt = ChatPromptTemplate.from_template(prompt_tmpl)
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0, api_key=settings.GOOGLE_API_KEY)
    # llm = ChatAnthropic(model="claude-3-7-sonnet-20250219", temperature=0, api_key=settings.ANTHROPIC_API_KEY)
    
    final_text = (prompt | llm).invoke({
        "instructions_text": instructions_text,
        "action_decision_json": to_json(action_decision),
        "option_candidates_json": to_json(option_candidates),
        "t2s_table_json": to_json(t2s_table),
        "web_search_json": to_json(web_search),
        "scraped_pages_json": to_json(scraped_pages),
        "marketing_trend_results_json": to_json(marketing_trend_results),
        "youtuber_trend_results_json": to_json(youtuber_trend_results),
        "knowledge_snippet": knowledge_snippet or "",
    })

    final_response = getattr(final_text, "content", None) or str(final_text)
    logger.info(f"ìµœì¢… ê²°ê³¼(L):\n{final_response}")
    history = state.get("history", [])
    history.append({"role": "user", "content": state.get("user_message", "")})
    history.append({"role": "assistant", "content": final_response})
    
    # logger.info(f"{state}")
    return {"history": history, "user_message": "", "output": final_response}

# ===== Graph =====
workflow = StateGraph(OrchestratorState)

workflow.add_node("planner", planner_node)
workflow.add_node("slot_extractor", slot_extractor_node)
workflow.add_node("action_state", action_state_node)
workflow.add_node("options_generator", options_generator_node)
workflow.add_node("tool_executor", tool_executor_node)
workflow.add_node("visualizer", visualizer_caller_node) 
workflow.add_node("response_generator", response_generator_node)

workflow.set_entry_point("planner")

workflow.add_conditional_edges(
    "planner",
    _planner_router,
    {
        "slot_extractor": "slot_extractor",
        "tool_executor": "tool_executor",
        "response_generator": "response_generator",
    },
)

workflow.add_edge("slot_extractor", "action_state")
workflow.add_conditional_edges(
    "action_state",
    _action_router,
    {
        "options_generator": "options_generator",
        "response_generator": "response_generator",
    },
)
workflow.add_edge("options_generator", "response_generator")

workflow.add_conditional_edges(
    "tool_executor",
    _should_visualize_router,
    {
        "visualize": "response_generator",
        "skip_visualize": "response_generator"
    }
)
workflow.add_edge("visualizer", "response_generator")
workflow.add_edge("response_generator", END)

orchestrator_app = workflow.compile()