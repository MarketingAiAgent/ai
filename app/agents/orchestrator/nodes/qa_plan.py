from __future__ import annotations

import json
import logging
from typing import Dict, List, Optional, Literal, Tuple

from pydantic import BaseModel, Field
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from langchain_google_genai import ChatGoogleGenerativeAI

from app.agents.orchestrator.state import AgentState, QAPlan
from app.core.config import settings

logger = logging.getLogger(__name__)


# -------------------- Prompt --------------------

def _build_messages(history: List[str], question: str) -> List[Tuple[str,str]]:
    system = (
        "ë„ˆëŠ” ë§ˆì¼€íŒ… Q&A ë¼ìš°í„°ë‹¤. ì•„ë˜ JSONì„ ì¶œë ¥í•˜ë¼ (ì„¤ëª…/ì—¬ë¶„ ê¸ˆì§€).\n"
        "{\n"
        '  "mode": "pass" | "augment",\n'
        '  "augment": "ì§ˆë¬¸ì´ ëª¨í˜¸í•  ë•Œ ìµœì†Œ ë³´ì¶© í•œ ì¤„(í•œêµ­ì–´)" | null,\n'
        '  "use_t2s": true | false,\n'
        '  "use_web": true | false,\n'
        '  "web_source": Literal["supabase_marketing" | "supabase_beauty" | "tavily"],\n'
        '  "need_visual": true | false\n'
        "}\n"
        "ê·œì¹™:\n"
        "- ì§ˆë¬¸ì´ ë‚´ë¶€ ìˆ˜ì¹˜/ì§€í‘œ/ì¶”ì´ë©´ use_t2s=true, use_web=false.\n"
        "- ì—…ê³„/ì‚¬ë¡€/íŠ¸ë Œë“œ/í‚¤ì›Œë“œ/ì¸í”Œë£¨ì–¸ì„œ/ë¦¬í¬íŠ¸ ë“±ì€ use_t2s=false, use_web=true.\n"
        "- ìœ ì €ê°€ ì¶”ì„¸ë¥¼ ë³´ì—¬ë‹¬ë¼ëŠ” ë“±ì˜ í˜•ì‹ìœ¼ë¡œ ì§ˆë¬¸ì„ í•˜ì—¬ ì‹œê°í™” í•„ìš”í•  ê²½ìš° need_visual=true ì•„ë‹ˆë¼ë©´ false.\n"
        "- ì™¸ë¶€ ì§€ì‹ í•„ìš”ë¡œ í•˜ì—¬ use_web=true ì¼ ë•Œ web_sourceì— ì–´ë–¤ ì†ŒìŠ¤ë¡œ ì •ë³´ë¥¼ ì–»ì„ì§€ ì¶”ê°€í•˜ë¼. (ì˜ˆ: ['supabase_marketing', 'supabase_beauty', 'tavily'])\n"
        "- ì§ˆë¬¸ì´ ì¶©ë¶„íˆ êµ¬ì²´ì ì´ë©´ mode=pass, ì• ë§¤í•˜ë©´ mode=augmentë¡œ í•œ ì¤„ë§Œ ë³´ì¶©(ì˜ˆ: ê¸°ê°„, ê·¸ë ˆì¸, ì„¸ë¶„í™”).\n"
        "- ìŠ¤í‚¤ë§ˆ/í…Œì´ë¸”/ì»¬ëŸ¼ëª… ì–¸ê¸‰ ê¸ˆì§€. ìì—°ì–´ë§Œ."
    )
    fewshot = [
        ("human", json.dumps({"history":["ì±„ë„ë³„ë¡œë„ ë´¤ê³ "], "question":"ì§€ë‚œ 1ë…„ê°„ ì—°ë ¹ëŒ€ë³„ ë°©ë¬¸ìˆ˜ ì¶”ì´ ë³´ì—¬ì¤˜"}, ensure_ascii=False)),
        ("ai", json.dumps({"mode":"pass","augment":None,"use_t2s":True,"use_web":False,"need_visual":True}, ensure_ascii=False)),
        ("human", json.dumps({"history":["ì‹ ê·œ ìœ ì…ì´ ì¤„ì—ˆì–´"], "question":"ì±„ë„ ì„±ê³¼ ì¢€ ë³´ì—¬ì¤˜"}, ensure_ascii=False)),
        ("ai", json.dumps({"mode":"augment","augment":"ìµœê·¼ 30ì¼ ê¸°ì¤€, ì±„ë„ë³„ í•µì‹¬ ì§€í‘œë§Œ ê°„ë‹¨ ë¹„êµí•´ì¤˜","use_t2s":True,"use_web":False,"need_visual":False}, ensure_ascii=False)),
        ("human", json.dumps({"history":["ì—¬ë¦„ ìº í˜ì¸ ì¤€ë¹„"], "question":"ë·°í‹° ì¸í”Œë£¨ì–¸ì„œ íŠ¸ë Œë“œ í•µì‹¬ í‚¤ì›Œë“œ ì•Œë ¤ì¤˜"}, ensure_ascii=False)),
        ("ai", json.dumps({"mode":"pass","augment":None,"use_t2s":False,"use_web":True,"need_visual":False}, ensure_ascii=False)),
    ]
    user = ("human", json.dumps({"history": history[-2:], "question": question}, ensure_ascii=False))
    return [("system", system), *fewshot, user]


# -------------------- Node --------------------

def qa_plan_node(state: AgentState) -> AgentState:
    logger.info("===== ğŸ“ QA í”Œë˜ë„ˆ ë…¸ë“œ ì‹¤í–‰ =====")

    history = state.history or []
    question = state.user_message or ""

    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0, api_key=settings.GOOGLE_API_KEY)
    parser = PydanticOutputParser(pydantic_object=QAPlan)

    try:
        msgs = _build_messages(history, question)
        out: QAPlan = (llm | parser).invoke(msgs)
        logger.info(f"QA í”Œë˜ë„ˆ ë…¸ë“œ ì‹¤í–‰ ê²°ê³¼: {out}")
        logger.info(f"===== ğŸ“ QA í”Œë˜ë„ˆ ë…¸ë“œ ì‹¤í–‰ ì™„ë£Œ =====")
        return {"qa_plan": out}
    except Exception:
        logger.exception("[qa_route_node] ì‹¤íŒ¨ â†’ pass-through ê¸°ë³¸")
        out = QAPlan(mode="pass", augment=None, use_t2s=True, use_web=False, need_visual=True)
        return {"qa_plan": out}