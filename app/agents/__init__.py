import json
import time

from langchain_google_genai import ChatGoogleGenerativeAI

from .orchestrator.state import return_initial_state
from .orchestrator.graph import orchestrator_app

def stream_agent(history, active_task, conn_str, schema_info, message): 

    state = return_initial_state(history, active_task, conn_str, schema_info,message)

    yield f"data: {json.dumps({'type' : 'report_start'})}\n\n"

    for chunk, meta_data in orchestrator_app.stream(state, stream_mode='messages'):
        if chunk.content: 
            for char in chunk.content:
                char_chunk_data = {"type": "text_chunk", 'content': char}
                yield f"data: {json.dumps(char_chunk_data)}\n\n"

                time.sleep(0.02)

    yield f"data: {json.dumps({'type': 'done'})}\n\n"

# def stream_example_agent(message: str):
#     """
#     LLMì˜ ì‘ë‹µì„ 'í•œ ê¸€ì ë‹¨ìœ„'ë¡œ ìª¼ê°œ SSE í˜•ì‹ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.
#     """
#     llm = ChatGoogleGenerativeAI(
#         model="gemini-1.5-flash", 
#         temperature=0, 
#         google_api_key=settings.GOOGLE_API_KEY
#     )
    
#     yield f"data: {json.dumps({'type': 'report_start'})}\n\n"

#     for chunk in llm.stream(message):
#         if chunk.content:
#             # ğŸ’¡ í•µì‹¬: ë°›ì€ ë°ì´í„° ë©ì–´ë¦¬(chunk)ë¥¼ í•œ ê¸€ìì”©(char) ìˆœíšŒí•©ë‹ˆë‹¤.
#             for char in chunk.content:
#                 # í•œ ê¸€ìë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ê°ì‹¸ì„œ ì „ì†¡í•©ë‹ˆë‹¤.
#                 char_chunk_data = {'type': 'text_chunk', 'content': char}
#                 yield f"data: {json.dumps(char_chunk_data)}\n\n"
                
#                 # (ì„ íƒ ì‚¬í•­) íƒ€ì´í•‘ íš¨ê³¼ë¥¼ ë” ëª…í™•í•˜ê²Œ ë³´ë ¤ë©´ ì•„ì£¼ ì‘ì€ ë”œë ˆì´ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
#                 time.sleep(0.02)

#     yield f"data: {json.dumps({'type': 'done'})}\n\n"