from __future__ import annotations

import logging 
import json 
from typing import List, Optional
from pydantic import BaseModel
from langchain_core.prompts import ChatPromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.output_parsers import PydanticOutputParser
from app.core.config import settings


logger = logging.getLogger(__name__)

from app.agents_v2.orchestrator.state import AgentState, PromotionSlots 

# ===== prompt =====
def _build_messages(history: List[str], current: str) -> List[tuple]:
    # ì§ì „ 4ê°œê¹Œì§€ë§Œ ì‚¬ìš©
    history = (history or [])[-4:]

    system = (
        "ë‹¹ì‹ ì€ í•œêµ­ì–´ë¡œ ë™ì‘í•˜ëŠ” ì •ë³´ ì¶”ì¶œê¸°ì…ë‹ˆë‹¤. "
        "ì…ë ¥ìœ¼ë¡œ ì´ì „ AI ì§ˆë¬¸ê³¼ í˜„ì¬ ìœ ì € ì‘ë‹µì„ ë³´ê³ , ë‹¤ìŒ í•„ë“œë§Œ JSONìœ¼ë¡œ ì¶”ì¶œí•´ ë°˜í™˜í•˜ì„¸ìš”:\n"
        "{{\n"
        '  "audience": string|null,\n'
        '  "scope": "ë¸Œëœë“œ"|"ì œí’ˆ"|null,\n'
        '  "target": string|null,\n'
        '  "period": string|null,\n'
        '  "KPI": string|null,\n'
        '  "concept": string|null\n'
        "}}\n\n"
        "ê·œì¹™:\n"
        "1) ì›ë¬¸ì— ëª…ì‹œë˜ì§€ ì•Šì€ ê°’ì€ ì¶”ì •í•˜ì§€ ë§ê³  nullë¡œ ë‘ì„¸ìš”.\n"
        "2) ê¸°ê°„ì€ ê°„ë‹¨ í‘œí˜„ ìœ ì§€(ì˜ˆ: 'ë‹¤ìŒ ë‹¬ 4ì£¼').\n"
        "3) ì„¤ëª…/ì£¼ì„ ì—†ì´ ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."
    )

    fewshot = [
        '''
history: [{{"speaker": "user", "content": "20ëŒ€ ëŒ€ìƒ í”„ë¡œëª¨ì…˜ í•´ë³¼ë˜!"}}, {{"speaker": "ai", "content": "ì¢‹ìŠµë‹ˆë‹¤. **ë¸Œëœë“œ ê¸°ì¤€**ê³¼ **ì œí’ˆ ê¸°ì¤€** ì¤‘ ì–´ëŠ ìª½ìœ¼ë¡œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"}}]
user_message: "ë¸Œëœë“œë¡œ ì§„í–‰í•´ì¤˜" 
output: {{"audience": "20ëŒ€", "scope": "ë¸Œëœë“œ", "target": null, "period": null, "KPI": null, "concept": null}}
''',
'''
history: [{{"speaker": "user", "content": "ë¸Œëœë“œë¡œ ê°€ì"}}, {{"speaker": "ai", "content": "ê¸°ê°„ì€ ì–´ë–»ê²Œ í•˜ì‹œê² ìŠµë‹ˆê¹Œ? ë‹¤ìŒ ë‹¬ 4ì£¼ë¡œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"}}]
user_message: "ë‹¤ìŒ ë‹¬ 4ì£¼ë¡œ"
output: {{"audience": null, "scope": "ë¸Œëœë“œ", "target": null, "period": "ë‹¤ìŒ ë‹¬ 4ì£¼", "KPI": null, "concept": null}}
'''
]

    user = ("human", json.dumps({"history": history, "user_message": current}, ensure_ascii=False))
    return [("system", system), *fewshot, user]

# ===== pydantic =====
class SlotExtractorOutput(BaseModel):
    audience: Optional[str] = None
    scope: Optional[str] = None
    target: Optional[str] = None
    period: Optional[str] = None
    KPI: Optional[str] = None
    concept: Optional[str] = None

# ===== Node =====
def slot_extractor_node(state: AgentState):
    logger.info("===== ğŸ§© ìŠ¬ë¡¯ ì¶”ì¶œ ë…¸ë“œ ì‹¤í–‰ =====")
    messages = _build_messages(state.history, state.user_message)
    prompt = ChatPromptTemplate.from_messages(messages)
    parser = PydanticOutputParser(pydantic_object=SlotExtractorOutput)
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0,
        model_kwargs={"response_format": {"type": "json_object"}},
        api_key=settings.GOOGLE_API_KEY
    )
    try:
        result: SlotExtractorOutput = (prompt | llm | parser).invoke()
        logger.info(f"ê²°ê³¼: {result}")
        logger.info(f"===== â“ ìŠ¬ë¡¯ ì¶”ì¶œ ë…¸ë“œ ì‹¤í–‰ ì™„ë£Œ =====")
        promotion_slots = state.promotion_slots.merge_missing(result.model_dump())
        return {"promotion_slots": promotion_slots}
    except Exception as e:
        logger.error(f"===== â“ ìŠ¬ë¡¯ ì¶”ì¶œ ë…¸ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ =====")
        logger.error(f"ì˜¤ë¥˜ ë‚´ìš©: {e}")
        return {"promotion_slots": None}