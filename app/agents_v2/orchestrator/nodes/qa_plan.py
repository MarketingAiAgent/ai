from __future__ import annotations

import json
import logging
from typing import Dict, List, Optional, Literal

from pydantic import BaseModel, Field
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from langchain_google_genai import ChatGoogleGenerativeAI

from app.agents_v2.orchestrator.state import AgentState
from app.core.config import settings

logger = logging.getLogger(__name__)

Choice = Literal["t2s", "web", "both", "none"]
AllowedSources = Literal["supabase_marketing", "supabase_beauty", "tavily"]


# -------------------- Schemas --------------------

class PlanningNote(BaseModel):
    """ìŠ¤í‚¤ë§ˆ/ì»¬ëŸ¼ëª…ì„ ëª¨ë¥¸ë‹¤ëŠ” ì „ì œì˜ CoT ìš”ì•½(êµ¬ì¡°í™”)."""
    user_intent: str
    needed_table: str                  # ì˜ˆ: "í–‰=ìš”ì¼, ì§€í‘œ=ì „í™˜ ê´€ë ¨ í•µì‹¬ ìš”ì•½"
    filters: List[str] = Field(default_factory=list)        # ê¸°ê°„/ì„¸ê·¸ë¨¼íŠ¸ ë“±(ìŠ¤í‚¤ë§ˆ ëª…ì‹œ ê¸ˆì§€)
    granularity: Optional[str] = None  # ì¼/ì£¼/ì›”, ìº í˜ì¸/ì±„ë„ ë“±
    comparison: Optional[str] = None   # ì „ë…„ë™ê¸°/ì§ì „ê¸°ê°„ ë“±
    why_t2s: Optional[str] = None
    why_web: Optional[str] = None

class T2SPlan(BaseModel):
    enabled: bool = True
    instruction: Optional[str] = None  
    top_rows: int = 100
    visualize: bool = True
    viz_hint: Optional[str] = None     

class WebPlan(BaseModel):
    enabled: bool = True
    query: Optional[str] = None
    queries: List[str] = Field(default_factory=list)
    use_sources: List[AllowedSources] = Field(
        default_factory=lambda: ["supabase_marketing", "supabase_beauty", "tavily"]
    )
    top_k: int = 5
    scrape_k: int = 0

class QAPlan(BaseModel):
    choice: Choice
    planning: PlanningNote
    t2s: T2SPlan
    web: WebPlan


# -------------------- Prompt --------------------

def _build_messages(history: List[str], question: str) -> List[tuple]:
    system = (
        "ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… ë°ì´í„°/íŠ¸ë Œë“œ Q&Aë¥¼ ìœ„í•œ **í”Œë˜ë„ˆ**ì…ë‹ˆë‹¤.\n"
        "ì…ë ¥(íˆìŠ¤í† ë¦¬+ì§ˆë¬¸)ì„ ë³´ê³  ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë¡œë§Œ ë‹µí•˜ì„¸ìš”.\n"
        "{\n"
        '  "choice": "t2s" | "web" | "both" | "none",\n'
        '  "planning": {\n'
        '    "user_intent": "í•µì‹¬ ì˜ë„",\n'
        '    "needed_table": "ì›í•˜ëŠ” í‘œì˜ ì˜ë¯¸(í–‰/ì§€í‘œ)ì™€ ê´€ì ",\n'
        '    "filters": ["ê¸°ê°„/ì„¸ê·¸ë¨¼íŠ¸ ë“±(ìŠ¤í‚¤ë§ˆëª… ê¸ˆì§€)"],\n'
        '    "granularity": "ì¼/ì£¼/ì›” ë“±(í•´ë‹¹ ì‹œ)",\n'
        '    "comparison": "ì „ë…„ë™ê¸°/ì§ì „ê¸°ê°„ ë“±(í•´ë‹¹ ì‹œ)",\n'
        '    "why_t2s": "T2S ì´ìœ (ì„ íƒ)",\n'
        '    "why_web": "ì™¸ë¶€ ì§€ì‹ ì´ìœ (ì„ íƒ)"\n'
        "  },\n"
        '  "t2s": {\n'
        '    "enabled": true/false,\n'
        '    "instruction": "ìŠ¤í‚¤ë§ˆ ëª¨ë¦„. í‘œì˜ ì˜ë¯¸/í•„í„°/ì •ë ¬/ìƒìœ„ ì œí•œì„ ìì—°ì–´ë¡œ ì§€ì‹œ. ì²« ì»¬ëŸ¼ì€ name ê¶Œì¥.",\n'
        '    "top_rows": 100,\n'
        '    "visualize": true/false,\n'
        '    "viz_hint": "ì„ /ë§‰ëŒ€/íŒŒì´ ë“± íŒíŠ¸(ì„ íƒ)"\n'
        "  },\n"
        '  "web": {\n'
        '    "enabled": true/false,\n'
        '    "query": "ê°„ê²° ê²€ìƒ‰ì–´",\n'
        '    "queries": ["ëŒ€ì²´ ê²€ìƒ‰ì–´(ì„ íƒ)"],\n'
        '    "use_sources": ["supabase_marketing","supabase_beauty","tavily"],\n'
        '    "top_k": 5,\n'
        '    "scrape_k": 0\n'
        "  }\n"
        "}\n"
        "ê·œì¹™: ì»¬ëŸ¼/í…Œì´ë¸” ì´ë¦„ì„ ì¶”ì •/ê°•ì œí•˜ì§€ ë§ê³ , í‘œì˜ ì˜ë¯¸Â·í•„í„°Â·ì •ë ¬ì˜ ê°œë…ë§Œ ì§€ì‹œí•˜ì„¸ìš”. JSON ì™¸ í…ìŠ¤íŠ¸ ê¸ˆì§€."
    )

    fewshot = [
        ("human", json.dumps({
            "history": [],
            "question": "ìš”ì¼ë³„ ì „í™˜ìœ¨ ë¹„êµí•´ì¤˜. ì°¨íŠ¸ë„ ë¶€íƒ."
        }, ensure_ascii=False)),
        ("ai", json.dumps({
            "choice": "t2s",
            "planning": {
                "user_intent": "ìš”ì¼ë³„ ì „í™˜ìœ¨ ë¹„êµ ë° ì‹œê°í™”",
                "needed_table": "í–‰=ìš”ì¼, ì§€í‘œ=ì „í™˜ìœ¨ê³¼ ê´€ë ¨ í•µì‹¬ ì§€í‘œ",
                "filters": ["ê¸°ê°„: ì§€ë‚œë‹¬"],
                "granularity": "ìš”ì¼",
                "comparison": None,
                "why_t2s": "ë‚´ë¶€ ì „í™˜ ë°ì´í„° í•„ìš”"
            },
            "t2s": {
                "enabled": True,
                "instruction": "ì§€ë‚œë‹¬ ë°ì´í„°ë¥¼ ëŒ€ìƒìœ¼ë¡œ ìš”ì¼ ë‹¨ìœ„ í‘œë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”. "
                               "í‘œì˜ ì²« ì»¬ëŸ¼ì€ name(ìš”ì¼)ë¡œ í•˜ê³ , ì „í™˜ìœ¨ê³¼ í•µì‹¬ ì§€í‘œ 1~3ê°œë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”. "
                               "ì „í™˜ìœ¨ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•˜ê³  ìƒìœ„ 7ê°œ(ëª¨ë“  ìš”ì¼)ë§Œ í¬í•¨í•´ ì£¼ì„¸ìš”.",
                "top_rows": 100,
                "visualize": True,
                "viz_hint": "ìš”ì¼ë³„ ë§‰ëŒ€"
            },
            "web": {"enabled": False, "query": None, "queries": [], "use_sources": ["supabase_marketing","supabase_beauty","tavily"], "top_k": 5, "scrape_k": 0}
        }, ensure_ascii=False)),

        # Webë§Œ
        ("human", json.dumps({
            "history": ["ì—¬ë¦„ ì„±ìˆ˜ê¸° ëŒ€ë¹„ ìº í˜ì¸ ì¤€ë¹„ ì¤‘"],
            "question": "ë·°í‹° ì¸í”Œë£¨ì–¸ì„œ íŠ¸ë Œë“œ í•µì‹¬ í‚¤ì›Œë“œ ì•Œë ¤ì¤˜"
        }, ensure_ascii=False)),
        ("ai", json.dumps({
            "choice": "web",
            "planning": {
                "user_intent": "ë·°í‹° ì¸í”Œë£¨ì–¸ì„œ íŠ¸ë Œë“œ í‚¤ì›Œë“œ íŒŒì•…",
                "needed_table": "í‘œ í•„ìš” ì—†ìŒ",
                "filters": ["ê¸°ê°„: ìµœê·¼"],
                "granularity": None,
                "comparison": None,
                "why_web": "ì™¸ë¶€ íŠ¸ë Œë“œ/ë²¡í„° ì¸ë±ìŠ¤ í•„ìš”"
            },
            "t2s": {"enabled": False, "instruction": None, "top_rows": 100, "visualize": False, "viz_hint": None},
            "web": {
                "enabled": True,
                "query": "ë·°í‹° ì¸í”Œë£¨ì–¸ì„œ ìµœì‹  íŠ¸ë Œë“œ í‚¤ì›Œë“œ",
                "queries": [],
                "use_sources": ["supabase_marketing","supabase_beauty","tavily"],
                "top_k": 5,
                "scrape_k": 2
            }
        }, ensure_ascii=False)),

        # Both
        ("human", json.dumps({
            "history": ["ì‹ ê·œ ê³ ê° ìœ ì…ì´ ì¤„ì—ˆì–´."],
            "question": "ì±„ë„ë³„ ì‹ ê·œêµ¬ë§¤ìˆ˜ ì¶”ì´ë‘, ì—…ê³„ì—ì„œ ìš”ì¦˜ ë­ê°€ ë¨¹íˆëŠ”ì§€ ê°™ì´ ì•Œë ¤ì¤˜"
        }, ensure_ascii=False)),
        ("ai", json.dumps({
            "choice": "both",
            "planning": {
                "user_intent": "ë‚´ë¶€ ì‹ ê·œêµ¬ë§¤ìˆ˜ ì¶”ì´ ë¶„ì„ + ì™¸ë¶€ íŠ¸ë Œë“œ ë³´ê°•",
                "needed_table": "í–‰=ì±„ë„/ê¸°ê°„, ì§€í‘œ=ì‹ ê·œêµ¬ë§¤ìˆ˜ì™€ ê´€ë ¨ í•µì‹¬ ì§€í‘œ",
                "filters": ["ê¸°ê°„: ìµœê·¼ 8ì£¼"],
                "granularity": "ì£¼",
                "comparison": "ì§ì „ ê¸°ê°„ ëŒ€ë¹„",
                "why_t2s": "ë‚´ë¶€ ì±„ë„ ì„±ê³¼ í™•ì¸",
                "why_web": "ì—…ê³„ ìµœì‹  ì „ìˆ  ì°¸ê³ "
            },
            "t2s": {
                "enabled": True,
                "instruction": "ìµœê·¼ 8ì£¼ë¥¼ ëŒ€ìƒìœ¼ë¡œ ì±„ë„-ì£¼ ë‹¨ìœ„ í‘œë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”. "
                               "ì²« ì»¬ëŸ¼ì€ name(ì±„ë„)ë¡œ í•˜ê³ , ì‹ ê·œêµ¬ë§¤ìˆ˜ ë° ê´€ë ¨ í•µì‹¬ ì§€í‘œ 1~3ê°œ í¬í•¨. "
                               "ì§ì „ ì£¼ ëŒ€ë¹„ ë³€í™”ë¥¼ í¬í•¨í•´ ì¶”ì´ í•´ì„ì´ ê°€ëŠ¥í•˜ë„ë¡ ì •ë ¬/ì œí•œì„ ì ìš©í•´ ì£¼ì„¸ìš”(ìƒìœ„ ì±„ë„ ìœ„ì£¼).",
                "top_rows": 200,
                "visualize": True,
                "viz_hint": "ì±„ë„ë³„ ì£¼ê°„ ì¶”ì´ ì„ í˜•"
            },
            "web": {
                "enabled": True,
                "query": "ì´ì»¤ë¨¸ìŠ¤ ì‹ ê·œê³ ê° ìœ ì… ì „ìˆ  2025 íŠ¸ë Œë“œ ì‚¬ë¡€",
                "queries": [],
                "use_sources": ["supabase_marketing","supabase_beauty","tavily"],
                "top_k": 5,
                "scrape_k": 2
            }
        }, ensure_ascii=False)),
    ]

    user = ("human", json.dumps({"history": history[-4:], "question": question}, ensure_ascii=False))
    return [("system", system), *fewshot, user]


# -------------------- Node --------------------

def qa_plan_node(state: AgentState) -> AgentState:
    logger.info("===== ğŸ“ QA í”Œë˜ë„ˆ ë…¸ë“œ ì‹¤í–‰ =====")

    history = state.history or []
    question = state.user_message or ""

    prompt = ChatPromptTemplate.from_messages(_build_messages(history, question))
    parser = PydanticOutputParser(pydantic_object=QAPlan)
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0, api_key=settings.GOOGLE_API_KEY)

    try:
        plan: QAPlan = (prompt | llm | parser).invoke({})
        plan.t2s.top_rows = max(10, min(1000, plan.t2s.top_rows or 100))
        plan.web.top_k = max(1, min(10, plan.web.top_k or 5))
        plan.web.scrape_k = max(0, min(5, plan.web.scrape_k or 0))
        if not plan.web.query and plan.web.queries:
            plan.web.query = plan.web.queries[0]

        logger.info(f"ê²°ê³¼: {plan.model_dump()}")
        logger.info(f"===== ğŸ“ QA í”Œë˜ë„ˆ ë…¸ë“œ ì‹¤í–‰ ì™„ë£Œ =====")

        return {"qa_plan": plan.model_dump()}
    except Exception:
        logger.exception("[qa_plan_node] LLM ì‹¤íŒ¨ â†’ ì•ˆì „ í´ë°±")
        fallback = QAPlan(
            choice="t2s",
            planning=PlanningNote(
                user_intent="ê¸°ë³¸ ì§€í‘œ ì¡°íšŒ",
                needed_table="í–‰=í•µì‹¬ ê´€ì , ì§€í‘œ=í•µì‹¬ ìˆ˜ì¹˜",
                filters=["ê¸°ê°„: ìµœê·¼"],
            ),
            t2s=T2SPlan(
                enabled=True,
                instruction="ê°€ì¥ ìµœê·¼ ê¸°ê°„ì˜ í•µì‹¬ ì§€í‘œ í‘œë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”. ì²« ì»¬ëŸ¼ì€ nameìœ¼ë¡œ í‘œì‹œëª…ì„ ë„£ê³  ìƒìœ„ 20í–‰ë§Œ í¬í•¨í•´ ì£¼ì„¸ìš”.",
                top_rows=100,
                visualize=True,
                viz_hint=None
            ),
            web=WebPlan(enabled=False),
        )
        return {"qa_plan": fallback.model_dump()}
